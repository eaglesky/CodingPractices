Reference Books:
(1) Cracking the coding interview(outline and summary)
(2) An ultimate guide to coding interview, on read.amazon.com. (outline, summay and
problems)
(3) Coding manual by Fangqin Dai(outline and problems)
(4) Robert Sedgewick's Algorithms(algorithms reference)
(5) Introduction to algorithms(algorithms reference)
(6) Head first Java(language reference)
(7) Leetcode C++ solutions by Fangqin Dai(solutions)
(8) Element of Programming Interviews(EPI)(solutions)
(9) Leetcode OJ(problems and solutions)


1. Arrays and HashTables

Knowledge:
(1) Hash Tables -- implementation, performance, collision. Iteration each element
in it usually requires iterate each bucket.
Four ways of handling collisions: Chaining with linked lists, chaining with BST,
Open Addressing with Linear Probing, Quadratic Probing and Double Hashing. (See CTCI)
(2) Resizeable array
	Implementation: Vector(C++), ArrayList(Java)
	Performance: get, set is O(1), amortized time of add is O(1) and why. 
(3) Basic language syntax for array(fixed and dynamic), hash map and hash set.
(4) In Java, it's better to use constructor to get the shallow copy of ArrayList than
calling the clone method, since List interface does not have clone method.
(5) Implementation of equals and hashCode methods in Java(See <<Effective Java>>,
http://www.angelikalanger.com/Articles/JavaSolutions/SecretsOfEquals/Equals.html)

Problems:
(1)[Leetcode]First Missing Positive(Algorithm and Implementation*)
(2) K Sum problems. Can be solved using two approaches:
    a. Sort the input array first. Then using two pointers starting from the beginning
    and the end of the array, moving one of them towards the other each time based
    on the comparison of the sum of the two elements and target, until they meet.
    The two pointers process takes O(n) time. No extra space needed.
    b. Using a hash set of list of n elements to record the results and remove duplicates.
    Sort the input array first if K > 2. Cache the sums and their corresponding elements
    while iterating the array. 
    The result hash set has to be used to remove the duplicates for both approaches.

    No matter which approach to use, divide K into two parts first. Iterate the second part
    and hash or iterate using two pointers on the first part.

    Time complexity of k Sum problems: omega(n^ceil(k/2)), O(n^(k-1)).
    http://www.sigmainfy.com/blog/k-sum-problem-analysis-recursive-implementation-lower-bound.html

    (2.1) Two sum
        (2.1.1) Input array is random, find out one solution.
            - [Leetcode] Two sum(Algorithm).
        (2.1.2) Input array is random, find out all unique solutions.
    (2.2) Three sum
        (2.1.1) Input array is random, find out all unique solutions.
            - [Leetcode] Three sum(Algorithm).
            - [Leetcode] Three sum closest(Algorithm).
        (2.1.2) Find out the count of all triplets whose sum is less than the target:
            - [Leetcode] Three Sum Smaller(Algorithm*) Using two pointers to find
            out the count efficiently in linear time.
    (2.3) Four sum(Random input array, find out all unique solutions)
        -[Leetcode] Four sum(Algorithms*).
        -[Leetcode] Four Sum II(Algorithm)
(3) Remove duplicates(Maximum allowed duplicates == K). Two ways of checking duplicates!
    - [Leetcode] Remove Duplicates from Sorted Array(Best Algorithm*).
    - [Leetcode] Remove Duplicates from Sorted Array2(Best Algorithm**). Best algorithm
    is very tricky. Still need to master the common solution.
(4) Two pointers:
    - [Leetcode] Previous three sum problems.
    - [Leetcode] Container with most water(Algorithm)
    - [Leetcode] Trapping rain water(Multiple Algorithms** and implementation*)
    - [Leetcode] Intersection of Two Arrays I and II(Algorithm when the arrays are
    sorted*). Remember the algorithm for sorted arrays.
    - [Leetcode] Move Zeros(Algorithms*). Remember both algorithms and how to prove
    them!
(5) Subarray sums:
    - [Leetcode] Minimum Size Subarray Sum(Algorithms*). This subarray question can
    often be handled by either using DP or two pointers.
    Binary search can also be used by first creating cumulative sum array and then
    look at the diff between any two elements in this array.
    - [Leetcode] Maximum Size Subarray Sum Equals k(Algorithm*). Use the third approach.
    - [Lintcode] Subarray Sum Closest(Algorithms*). Remember the algorithm that find
    out the closest two elements in an unsorted array in O(nlogn) time.
    - [Lintcode] Submatrix Sum(Algorithms*). Remember how to enumerate all the sub
    rectangles in a 2D matrix. Remember the trick to add padding zeros.
    - [Leetcode] Max Sum of Rectangle No Larger Than K(Algorithm*). Extension of above.
    Remember the best solution.
(6)[Others] Task schedule with cool down.(Algorithm and implementation*).
(7)[Leetcode] Count and Say. Clarification: The question is to find the nth string
in the given string sequence starting with "1". For example, n = 1, return "1"; n
= 2, return "11"; ... n = 5, return "111221".


2. Strings

Knowledge:
(1)JAVA: String, StringBuilder and char[]. 
StringBuilder is essentially a wrapper of dynamic char array , and append(string)
basically copy each character from input string to the end of existing char array.
When deleting, it will shift the characters after those deleted forward. To remove
the last element in the StringBuilder, just use sb.setLength(sb.length() - 1). toString
() method returns a copy of wrapped char array, wrapped by a newly created String.
setCharAt(index, char) is also an useful method to update a certain char in the StringBuilder.
Also note that StringBuilder doesn't have isEmpty() method while String does.
char[] array usually has a better performance than StringBuilder since it is simpler.
But when dynamiccally adding new elements to it, usually another variable charLen
is needed to record the current length(number of filled elements in the array). Creating
a string from it is simply using new String(char[] value, int offset, int count).
char[] can make backtracking easier since you can just override the old elements when
searching a new branch. But StringBuilder is also usefully and saves you from maintaining
the length of the array.

(2)Palindrome.
    (2.1)Definition. A string that reads the same backward as forward, e.g., madam.
    Checking if a string is a palindrome can be easily done in O(n) time.
    (2.2)Check if concatenation of two strings is a palindrome. The reverse of the
    second string has to be the 1)the prefix of the first string, and the rest of
    the first string is a palindrome, or 2)the first string is the prefix of the reverse
    of second string, and the rest of the reversed string is a palindrome.
    [Leetcode]Palindrome Pairs.
    (2.3)Find out all the palindrome substrings. There are two ways to do this, which
    are very useful when solving more complex palindrome related problems. Both ways
    take O(n^2) time, n is the length of string s.
        (2.3.1)Let f[i][j] indicate whether substring s[i...j] is a palindrome or
        not. Iterate the string from right to left, for each character s[i], check
        all substrings s[i..j], i <= j < s_length.
        f[i][j] = (s[i] == s[j]) && (j - i < 2 || f[i+1][j-1])).
        f[i][j] can be reduced to 1D if j starts from s_length - 1. Remember!
        (2.3.2)Iterate the string from left to right. For each character s[i], check
        the substrings that center at it of odd and even lengths.
            for (int i = 0; i < s.length(); ++i) {
                //Odd length.
                for (int j = 0; i-j >= 0 && i+j < len && s.charAt(i-j) == s.charAt(i+j); ++j) {
                    f[i-j][i+j] = true;
                }
                //Even length.
                for (int j = 0; i-1-j >= 0 && i+j < len && s.charAt(i-1-j) == s.charAt(i+j); ++j) {
                    f[i-1-j][i+j] = true;
                }
            }
    Example: [Leetcode] Palindrome Partitioning II.
    (2.4)Finding the longest palindrome starting from a certain letter in a string
    can be solved in O(n) time and O(n) space using KMP pre-processing algorithm.
    No need to know the implementation details, but need to know the time and space
    complexities of KMP. The actual string matching part of KMP takes O(m) time, where
    m is the length of the string being matched. So the totol time is O(m + n).
    --- [Leetcode]Shortest Palindrome(Algorithm*, very hard!)
(3)Don't forget the edge case when the string is empty! If this happens, for loop
on the string won't happen!
(4)Anagram: a word, phrase, or name formed by rearranging the letters of another,
such as cinema, formed from iceman. To check if two strings are anagrams, either use
a hashmap to count the number of occurences for each character and compare them, or
just sort the two strings and see if they are the same.
(5)Note that the whitespace in a string may not be ' ', could be '\t' or even '\n'.
(6)For string parsing problems, try coming up with a working solution first and don't
consider any performance related issues at first. 

Problems:
(1)Numbers related
    Pay attention to how to handle substrings starting with 0, like '0001'.
    - [Leetcode]Integer To Roman(Algorithm*)
    - [Leetcode]Roman To Integer(Algorithm*)
    - [Leetcode]Basic Calculator II(Best Algorithm* and Implementation). Remember
    the best solution(very fundamental!). Also remember the way how to get integers
    formed by a substring without using Integer.parseInt(string). 
    - [Leetcode]Expression Add Operators(Algorithm* and Implementation*). Remember
    the best backtracking logic and implementation.
    - [Leetcode]Different Ways to Add Parentheses(Algorithm*).Remember the way of
    enumerating different order of calculating an arithmetic expression.
(2)Sliding window approach for substring problems:
    * Think about why sliding window approach would work first. It basically considers
    each substring that starts with the character at the left pointer and skip some
    by moving the left pointer. The substring within the sliding window(before the
    right pointer) often satisfies a certain condition. And usually the substrings
    starting from the characters in between don't satisfy that condition.
    We can also think of it checking each substring that ends with the character pointed
    by the right pointer.
    * A map of character to position or character to count should be created at the
    beginning. Sometimes one may not be enough. Especially when there are multiple
    input strings.
    * The main for loop is moving the right pointer and check each character to see
    if it should stop and begin moving the left pointer. Need to think very carefully
    about this check. When the check doesn't pass, usually we need to update the map,
    in some ways. (Sometimes the map should always be updated)
    * If the above check passes, then an inner loop should be performed to move the
    left pointer. Remember to update the result(max/min length) first. Depending on
    the specific problem, the left pointer can or cannot be moved to the destination
    directly. Also during this process we might need to remove or change some entries
    in the map.
    * Return the max/min result. May need to do one more comparision.

    Two basic implementations for sliding window problems:
    * Using one loop:
        Declare a map of char to pos or counts -- myMap;
        int maxOrMin;
        for (int i = 0; i < s.length();) {
            char c = s.charAt(i);
            if (Satify some condition related with myMap) {
                update myMap;
                update maxOrMin;
                update other auxilary variables related with above;
                ++i;
            } else {
                char preChar = s.charAt(start);
                update myMap;
                start++;
            }
        }
        return maxOrMin;

    * Using one outer loop with one inner loop, can be used for most of the hard
    problems.
        Declare a map of char to pos or counts -- myMap;
        int maxOrMin;
        for (int i = 0; i < s.length(); ++i) {
            char c = s.charAt(i);
            update myMap;//Might not need to remove elements
            update other auxilary variables related with above;
            for(; satifying some condition; ++start) {
                if the target is Min, may need to update maxOrMin here;
                update myMap;
                update other auxilary variables related with above;
            }
            if the target is Max, may need to update maxOrMin here;
        }
        return maxOrMin;

    - [Leetcode]Longest Substring Without Repeating Characters(Best Algorithm* and
    Implementation),
    - [Leetcode]Longest Substring with At Most K Distinct Characters(Algorithm* and
    Implementation*)
    - [Leetcode]Longest Substring with At Least K Repeating Characters(Multiple Algorithms*)
    - [Leetcode]Minimum Window Substring(Algorithm* and Implementation*), returned
    string must contain no less number of occurence of each character than that in
    T.
    - [Leetcode]Substring with Concatenation of All Words(Algorithm* and Implementation*,
    very hard). In this question, word list can contain duplicate word, and the target
    substring should contain exactly same number as appeared in the word list.
(3)Palindrome related.
(4)Anagram related.
    - [Leetcode]Group Anagrams(Algorithm*)
(5)Parsing.
    - [InterviewBit]Pretty Json(Best Algorithm* and Best Implementation*). Remember
    the best logic.



3. Linked Lists

Knowledge:
(1)Java: LinkedList class -- doubly linked list, performance
(2)Two pointers technique is frequently used! The diff between any two given linked
list can always be found in O(m+n) time.
(3)Two pointers iteration on two linked lists(one on each of them):
    (3.1)while (p != null || q != null) {
            if (p == null) {
                operation on q;
                q = q.next;
            } else if (q == null) {
                operation on p;
                p = p.next;
            } else {
                operation on both p and q(might have more branches here)
                p = p.next;
                q = q.next;
            }
        }
    (3.2)while (p != null && q != null) {
            operation on both p and q.(might have more branches here)
            p = p.next;
            q = q.next;
        }
        /*while (p != null) {
            operation on p.
            p = p.next;
        }
        while (q != null) {
            operation on q.
            q = q.next;
        }*/
        //another way
        v = p != null ? p : q;
        while (v != null) {
            ...
        }
        This approach is preferable if we can skip iterating the non-null list after
        the loop breaks. E.g. merge two sorted linked lists.
    (3.3)(probably best): while(p != null || q != null) {
                              if (p != null && (q == null || condition_of_iterate_p))
                              {
                                    operation on p.
                                    p = p.next;
                              } else {
                                    operation on q.
                                    q = q.next
                              }
                          }
   The above implementations can also be appied to two pointers iteration on arrays
   or strings. E.g. The merge function of Merge Sort. 
(4)Sometimes we can use the input pointers to reduce the number of pointers created.
(5)It is possible to delete a node only by using that pointer if that node is not
the head or tail --- by shifting the contents of the following nodes toward it and
remove the last one.
(6)Adding dummy node to the front a linked list can be convenient for iterating over
the list using two pointers, especially if we want to remove the first node, or insert
in front of the first node. Think carefully about edge cases involving the head node
if we do not want to add the dummy node(for node finding problems, think about the
case when there is only one node in a list).
(7)Edge cases: (think normal case first), insert/remove the first/last node, one node
linked list, null list.
(8)Three approaches for reversing linked list and their implementation(see below).
Use previous node pointer instead of the current node pointer if we want to move the
current node around or remove a node. 

Problems:
(1)Node finding:
    - [Leetcode]Intersection Of Two Linked Lists(Best Algorithm* and Best Implementation*)
 Remember this algorithm(including the first trial)!
    - [Leetcode]Linked List Cycle II(Algorithm* and Implementation*)
(2)Remove nodes: 
    - [Leetcode]Remove Nth Node From End of List(Implementation, practice dummy node,
    two pointers moving and edge case thinking)
    - [Leetcode]Remove duplicates from sorted list I(easy) and II(Implementation*)
    - Generalization of above to allow K duplicates -- Remove duplicates from sorted
    list III.(Implementation* -- multiple cases). Not found in any OJ. I implemented
    the test cases.
(3)Reverse nodes: 
	(3.1)Basic head insertion(Iterative and recursive) -- creating a new linked list,
    original head pointer will become tail pointer, and the new head pointer keeps
    updating. No need for the dummy node.
	   - [Leetcode] Reverse Linked List(Implementation, recursive algorithm*)
	(3.2)Head insertion for reversing sublists -- This process includes node removing
    and node insertion. Must add dummy node. The predecessor of the head of the original
    sublist now becomes the predecessor of the tail of the reversed sublist. So the
    predecessor of each sublist is enough to reverse the sublist and get the new head
    and tail of the reversed sublist.
	   - [Leetcode]Swap Nodes in Pairs(Implementation)
	   - [Leetcode]Reverse Nodes in K-Group(Algorithm* and Implementation*)
	   - [Leetcode]Reverse Linked List II(Implementation*)
	(3.3)Tail insertion. Inserting each node right after the original tail node. Need
    to first aquire pointer to the tail node and then start from the first node. Original
    tail node will become new head node. Pointer to the sucessor of the original tail
    node need to be stored or it will be lost.
    - [Leetcode]Reverse Nodes in K-Group(Algorithm* and Implementation*)
(4)Re-arrange nodes:
    Removing nodes first, and then either insert them into the original list or a
    new list. The latter way requires creating a new dummy node and tail node for
    appending, more nodes than the former way but could be simpler. The former way
    need to deal with some special cases, like removing and inserting into the old
    place, which could affect the next position of the pointer.
    - [Leetcode]Rotate List(Algorithm*, practice two pointers moving--two ways)
    - [Leetcode]Partition List(Best algorithm*)
(4)Copy linked list:
	- [Leetcode]Copy List with Random Pointer(Algorithm*, two approaches)




4. Stack and Queue

Knowledge:
(1)A stack can be implemented with a resizable array or a linked list; A queue can
be implemented with a cyclic array, double resizeable arrays or a linked list.
(2)Java implemenation: 
Interfact Deque<E>, push(E item), pop(), peek(). 
Interface Queue<E>, offer(e), poll(), peek(). 
Iteration using iterator and descendingItarator -- different results!
Both of them can be implemented as class ArrayDeque<E>, which is essentially a cyclic
array implemented with a array. According to java doc, "This class is likely to
be faster than Stack when used as a stack, and faster than LinkedList when used as
a queue". The Deque interface usually doesn't allow null element, as peek() returns
null when the deque is empty. peek() does not throw any exceptions. ArrayDeque doesn't
permit null element while LinkedList does. Stack interface permits null element too.
However try not to put null element in all cases.
Java ArrayDeque can be used to implement monotonic queue(see [Leetcode]Sliding Window
Maximum). Note that peek(), poll(), push() and pop() are all performed on the head
of the queue. offer(), peekLast(), pollLast() are performed on the tail.
(3)In some design problems, sometimes it is good to call peek() first in pop()/poll
().

Problems:
(1)[Leetcode]Simplify path(Implementation*)
(2)[Leetcode]Evaluate reverse polish notation(Implementation)
(3)[Leetcode]Min stack(Multiple algorithms*, practice conversion between primitive
types and Binary Numeric Promotion)
(4)[Leetcode]Implement queue using stacks(Algorithm*)
(5)[Leetcode]Implement stack using queues(Best Algorithm*)
(6)[Leetcode]Longest Valid Parentheses(Algorithms*). Very good problem that demos
two ways of handling parentheses related problems.
(7)[Leetcode]Largest Rectangle in Histogram(Algorithm*).
(8)[Leetcode]Maximal Rectangle(Algorithm)
(9)[Leetcode]Sliding Window Maximum(Algorithm* and Implementation*)
(10)[Leetcode]Basic Calculator(Algorithms* and Implementations*)


5. Trees

Knowledge:
(1)Definition of tree, binary tree and binary search tree, and the differences between
them. For BST, definition can vary slightly with respect to equality, if there could
be duplicate values.
(2)Balanced vs Unbalanced. Two common types of balanced (binary search) tree are red-black
tree and AVL tree. Usually the height of a balanced BST is O(log(N)). Search, insertion
and deletion all take O(logN) time. Java implementation: TreeMap, based on red-black
tree.
(3)Definition of complete, full and perfect binary trees.
(4)Number of nodes in perfect binary tree: n = 2^k - 1 (k is the number of levels)
(5)Binary tree inorder, preorder and postorder traversal and their three implementations
(see related problems below, remember the implementation of them except Morris). --
N-ary trees?
(6)About Morris traversal: the basic idea is to use null right child of some nodes
to store the succedents beforehand and delete them afterhand. Preorder and inorder
are similar, since the right children are always traversed at last, and therefore
after traversing back through the thread pointer there is no need to visit the left
children again. However for postorder traversal, the parent node is traversed at last.
So after traversing back through the thread pointer, the left children have to be
visited reversely(only those nodes from the direct left child all the way down to the
right). It is also necessary to create a dummy node and(7) have its left child be the
root.
(7)If the problem is about the height(distance from the leaf), consider to compute
the height for each node recursively, based on that of its children.
E.g. [Leetcode]Find leaves of binary tree. This solution can be applied to finding
all the nodes with different height at each level with minor changes(max -> min).
Note that the code of finding the minimum height/depth is more complex than finding
the maximum! For the minimum, usually need to check if both children are not null,
else if one of them is null, else both are null.
When finding the max depth, consider treating null as depth -1. This is usually the
preferred approach if some kind of pre-validation need to be done.
Besides traditional top-down approach, max-depth problem can also be solved by removing
the leaf nodes in each iteration until the tree is empty.
E.g. [Others]Find Depth.
(8)Binary search tree:
    (7.1)Definition
    (7.2)Ascending order when doing inorder traversal on it
    (7.3)Search, Minimum, Maximum, (inorder)Successor, (inorder)Predecessor operations
    all run in O(h) time. h is the height of the BST. See the Leetcode practices for
    Successor implementation.
    (7.4)Insertion(easy) and Deletion(harder, see one example problem) can also run
    in O(h) time.
    (7.5)Selection and Rank. See Leetcode problem below.
    (7.6)Range query -- finding all elements in a BST that have values within a given
    range. See Robert's Algorithms. O(n) time and O(h) space
(9)Trie(Prefix tree/radix tree/digital tree):
    (8.1)Refer to Robert's Algorithms. Think of the chars on the link instead of on
    the node.
    (8.2)The map in each node can be implemented with hashmap or array.
    (8.3)See the first two leetcode problems for complete implementation of trie methods.
    (8.4)The value of each node can be boolean, integer, or even a String -- representation
    of the word from the root to the node. And this value can change and be used for
    de-duplication. E.g. [Leetcode] Word Search II.

Problems:
(1) Traversal:
    - [Leetcode]Binary tree inorder traversal(Algorithms* and Implementation*)
    - [Leetcode]Binary tree preorder traversal(Algorithms* and implementation)
    - [Leetcode]Binary tree postorder traversal(Algorithms* and implementation), it
    can be seen as a reverse of preorder traversal. Hardest among the three.
    - [Leetcode]Binary tree level order traversal I(Multiple algorithms*), II is
    just adding reverse to the end of the solution of I.
    - [Leetcode]Zigzag level order traversal. Reverse the array for
    that level every two levels(or assign the values reversely when creating the array
    for that level).
    - [Leetcode]Binary Tree right side view -- small variation of level order traversal.
    - [Leetcode]Symmetric Tree(Algorithm and Multiple Implementation*). Iterative
    solution using queue or stack can add the elements in any order.
    - [Leetcode]Balanced binary tree(Best Implementation*)
    - [Leetcode]Populating next right pointers in each node I and II(Implementation)
    - [Leetcode]Flatten binary tree to linked list(Multiple Algorithms*)
    - DFS for all the paths: [Leetcode]Path Sum I and II(Implementation). Current
    path needs to be copied first and then put into the result array.
    - [Leetcode]Lowest Common Ancestor of a Binary Tree(Algorithms*). Building a map
    of node to its parent node while traversing the tree could help solve some problems.
    - [Leetcode]Find leaves of binary tree(Algorithm* and Implementation). When requiring
    return a list of nodes that does not follow the order of basic traversal, consider
    storing the element directly to the corresponding location in the output array.
    - [Leetcode]House Robber III(Algorithm)
    - [Leetcode]Binary Tree Vertical Order Traversal(Algorithm*). When implementing
    level order traversal, sometimes it is easier to handle the current node directly
    instead of handle the left and right node respectively.
(2) Recontruction of binary tree:
    - [Leetcode]Construct Binary Tree from Inorder and Postorder Traversal (Algorithm*
    and Implementation*), and Construct Binary Tree from Preorder and Inorder Traversal
    (same). Cannot construct the binary tree from Preorder and Postorder(why? When
    coming up with exceptions, try starting with the simplest examples)
    Note that if duplicates exist in the input array, there may not be unique tree!
    - [Leetcode]Serialize and Deserialize Binary Tree(Algorithm*)
(3) Binary Search Tree:
    - [Leetcode]Validate Binary Search Tree(Multiple algorithms* and Implementations*)
        -- this reveals an important attribute of BST when traversing it!
    - [Leetcode]Recover Binary Search Tree(Algorithm and Implementation). Note that
    this question assumes there are no duplicates in BST! What would be the solution
    if there could be duplicates?
    - [Leetcode]Convert Sorted Array to Binary Search Tree(Algorithms and Iterative
    Implementation*)
    - [Leetcode]Convert Sorted List to Binary Search Tree(Best Algorithm* and Implementations*),
    constructing tree from array can also be solved by bottom-up approach!
    - [Leetcode]Inorder Successor in BST(Algorithm*). This algorithm uses the ascending
    order attribute of BST so that it can run in O(h) time not in O(n) time. Therefore
    this algorithm works only when the target is INORDER successor and there are no
    duplicates in the tree. If duplicates are allowed, this algorithm can not gurantee
    that the node returned is INORDER successor. Example:
            13
          10
        9
          10(returned node)
            10 (look-up node)    
    This algorithm can be easily extended to implement Ceiling and Floor methods.
    - [Leetcode]Delete Node in a BST(Algorithms* and Implementation)
    - [Leetcode]Kth Smallest Element in a BST(Multiple Algorithms*)
    - [Leetcode]Lowest Common Ancestor of a Binary Search Tree(Algorithm*)
    - [Leetcode]Serialize and Deserialize BST(Algorithm* and implementation). Remember
    the algorithm and implementation. Be careful about the integer pointer!
    - [Leetcode]Skyline Problem(Algorithms* and implementations*). Remember the two
    ways of implementing BST multi-map/set. They are equivelent in logic, so don't
    hesitate to use them exchangely. The implementation logics of both solutions are
    pretty hard to come up with!
(4) Trie:
    - [Leetcode]Implement Trie (Prefix Tree)(Full Implementation*, recursive solution
    of delete?)
    - [Leetcode]Add and Search Word - Data structure design(Implementation)
    - [Leetcode]Palindrome Pairs(Multiple Algorithms** and Implementations**).(Distinct
    indices (i, j) just means that i != j) One way to improve the speed of not optimal
    algorithm is consider caching some values when building the trie. Remember the
    edge cases for the second approach.
(5) Others:
    - [Others] Find Depth. (Algorithms* and implementations*).

6. Graph

Knowledge:
(1)Representations(Refer to CTCI):
    (1.1)Adjacency list. V(number of Vertices) + E(number of edges) space for directed
    graph, or V + 2E for undirected graph. This is usually the preferred representation.
    Works well when accessing the neighbors is frequent. For fast edge lookup, just
    use hashset of integers(instead of list) as the element of arrays in the Graph
    class(Refer to the implementation of adjacency list in Robert's Algorithms).
    The list can be implemented with a HashMap or ArrayList. The former works better
    if the graph is sparse and  it doesn't require initializing each element. However
    need to know that when creating the map, if the graph is directed, the node without
    outbounding edges will not be inserted. So when getting the adjacent elements
    of a node, first check if the corresponding adjacency list in the map is null!
    (2.2)Adjacency matrix. V*V space. Fast for edge lookup, easier to represent weights,
    but usually takes more space than adjacency list. And has no way to represent
    parallel edges.
(2)Traversal. Don't forget null input node and loops!
Also note that the following pseudocode only implements traversing from one node.
If the graph is not connected, then DFS and BFS below must be called for each node!
The following template is just used for implementation. Think about the problem itself
when considering the algorithm -- like what parameters to use in the recursive
functions and what they do in each recursion.
(2.1)DFS. Can be used for counting the number of connected components in
a graph, check if two vertices are connected, etc. Implemented recursively. Iterative
solution usually uses a stack(of actual element or iterator of lists of elements.
Often used as step-by-step backtracking and implementing iterators. E.g. [Leetcode]Flatten
Nested List Iterator). And a map of node to its parent can be created while traversing
to retrieve the paths.
    * Algorithm of DFS(node, visited)
        if node is null, return; //Can be omitted sometimes
        visit(node)
        visited[node] = true; //Usually a hashmap. Flexible, can vary a bit depending
                              //on the problem
        for (adjNode : node.adjNodes) {
            if (visited(adjNode) == false) {
                DFS(adjNode, visited)
            }
        }
        Done;

    * Setting the visited node can also be done before iterating each adjNode, like
    below:
    Small variation of DFS(node)
        if node is null, return;
        visit(node);
        visited[node] = true;
        DFS(node, visited);
        Done;

    DFS(node, visited):
        for (adjNode : node.adjNodes) {
            if (visited(adjNode) == false) {
                visited[adjNode] = true;
                visit(adjNode);
                DFS(adjNode, visited);
            }
        }
        Done;

    * Checking if the adjNode is valid can also be done inside the recursive function
    --- at the beginning if the curNode is not valid, return. This is often used in
    matrix searching where four direction need to be searched. If the adjacent values
    need to be compared first before deciding whether to go to that direction or not,
    we can add "preValue" to the DFS function arguments. 
    E.g. [Leetcode]Pacific Atlantic Water Flow.

    * Finding all the paths between two states:
        main:
            visited[node] = true;
            DFS(node, curPath, paths); //Initialize the capacity of curPath if possible!
            return paths;

        DFS(node, curPath, paths):
            if node is end node:
                paths.add(curPath.shallow_copy);
                return;

            for (adjNode : node.adjNodes) {
                if (isValid(adjNode, visited)) { //Pruning is in isValid
                        //Pruning can be added later as refactoring,
                        //which might be better if the problem is very complex
                    curPath.add(adjNode);
                    visited[adjNode] = true;
                    DFS(adjNode, curPath, paths);
                    curPath.removeLast; //This can be omitted if curPath is a fixed
                                        //size array. If so, upperId of the array
                                        //should be increased by 1 and passed to DFS
                                        //recursive function
                    visited[adjNode] = false;
                }
            }
            Done;

    * Variation of above:
        main:
            DFS(node, curPath, paths); //Initialize the capacity of curPath if possible!
            return paths;
            
        DFS(node, curPath, paths):
            if node is end node:
                paths.add(curPath.shallow_copy);
                return;
            //isValid can also be called here instead of later, usually must be after
            //checking if the node is end node!
            curPath.add(node);
            visited[node] = true;
            for (adjNode : node.adjNodes) {
                if (isValid(adjNode, visited)) {
                    DFS(adjNode, curPath, paths);
                }
            }
            curPath.removeLast;
            visited[node] = false;
            Done;
        Example: [Leetcode]Course Schedule I and II.
(2.2)BFS. Usually used for finding the shorted path(s) between two vertices. Implemented
    iteratively using queue, O(V + E) time. 
    * Algorithm of BFS(node)
        If node is null, return; //queue usually doesn't allow null value
        Create queue q;
        q.enqueue(node);
        visited[node] = true; //Usually a hashmap. Flexible, can vary a bit depending
                              //on the problem. This must be set true before enqueuing
                              //each element
        while (!q.isEmpty) {
            curNode = q.dequeue();
            visit(curNode);
            for (adjNode : curNode.adjNodes) {
                if (visited(adjNode) == false) {
                    visited(adjNode) = true; // This must be set true before enqueuing
                                             //each element
                    prev[adjNode] = curNode; //Record the predecessor, used when you
                                             //want the shorted path
                    q.enqueue(adjNode);
                }
            }
        }
        print(prev) // Print out the shortest path recursively, optional
        done;

    * Algorithm of level BFS(node), which can give the distance from the node being
    traversed to the source node
        If node is null, return; //queue usually doesn't allow null value
        Create queue q;
        q.enqueue(node);
        visited[node] = true; //Usually a hashmap. Flexible, can vary a bit depending
                              //on the problem
        for (level = 0; !q.isEmpty; ++level) {
            size = q.size();
            for (i = 0; i < size; ++i) {
                curNode = q.dequeue();
                visit(curNode);
                for (adjNode : curNode.adjNodes) {
                    if (visited(adjNode) == false) {
                        visited[adjNode] = true;
                        prev[adjNode] = curNode;  //optional
                        q.enqueue(adjNode);
                    }
                }          
            }
        }
        print(prev)  //optional
        done;

    * BFS(node, endNode) finding all the shortest paths: (see [Leetcode]Word Ladder2)
        If node is null, return; //queue usually doesn't allow null value
        Create queue q;
        q.enqueue(node);
        str2Dis[node] = 1; //Map of node to the distance to the source node(level),
                           //also used for checking if the node has been visited
        prevs[node] = emptyList; //Map of node to list of its predecessors
        shortestDis = -1;
        while (!q.isEmpty) {
            curNode = q.dequeue();
            curDis = str2Dis.get(curNode);
            if (shortestDis > -1 && curDis >= shortestDis) {
                break;
            }
            visit(curNode);
            for (adjNode : curNode.adjNodes) {
                if (adjNode == endNode) {
                    shortestDis = curDis + 1;
                }
                if (!str2Dis.containsKey(adjNode)) {
                    str2Dis[adjNode] = curDis + 1;
                    prev[adjNode].add(curNode); 
                    q.enqueue(adjNode);
                } else if (str2Dis.get(adjNode) == curDis + 1) {
                    prev[adjNode].add(curNode);
                }
            }
        }
        getPaths(endNode, prev, pathList, pathLists)
        done;

        getPaths(endNode, prev, pathList, pathLists): //DFS finding all paths
            prevNodes = prev.get(endNode);
            if (prevNodes == null) { //There could be no path to endNode at all!
                return;
            }
            pathList.add(endNode); //If we add to the front here, then there is no
                                   //need to reverse later
            for (prevNode : prevNodes) {
                getPaths(prevNode, prev, pathList, pathLists);
            }
            if (prevNodes.isEmpty()) { //The root node has no predecessors
                pathListReversed = pathList.reverseCopy(); //Don't forget to make
                                                           //a copy first!
                pathLists.add(pathListReversed);
            }
            pathList.removeLastNode();
            done;


    * Bidirectional BFS. See [Leetcode]Word Ladder for implementation.

(3)Topological sort.(Refer to Robert's algorithms)
(3.1)Definition: Given a digraph, put the vertices in order such that all its directed
edges point from a vertex earlier in the order to a vertex later in the order (or
report that doing so is not possible).
(3.2)A digraph has a topological order if and only if it is a DAG(directed acyclic
graph, a digraph with no directed cycles). The topological order is not necessarily
unique.
(3.3)Algorithms that can detect if the given digraph is a DAG, and compute the topological
order if it is: 
    (3.3.1)BFS solution(Kahn's algorithm), refer to CTCI for description of the algorithm.
    The queue stores the topological sorted sequence.
    (3.3.2)DFS solution. Add the element to the stack right after each recursive function
    call and the reverse of the elements in the stack is the topological sorted sequence.
    The above solutions require to build a adjacency list first. If a has to be executed
    before b, then natually a->b is the edge. This works well for both of the above
    solutions.
    Example: [Leetcode]Course Schedule I and II.
(3.4)Given a sequence, does it satisfy the constraints? If so, is it the only sequence
that can be contructed from the constraints? Example: [Leetcode]Sequence Reconstruction,
not implemented yet.
Solutions:
    * Still use BFS solution above, but everytime before polling an element out from
    the queue, check if there are already more than 1 element in the queue. If so,
    then the result is not unique. Otherwise need to compare the polled element with
    the next element in the given sequence to see if they are matched.
    https://discuss.leetcode.com/topic/65948/java-solution-using-bfs-topological-sort/2
    O(V+E) time and O(V+E) space, the code is quite long.
    * A simpler and better algorithm is like this: 
        * To see if the given sequence satisfies the constraints, we can first create
        a map of sequnce element to its position, called pos, and check each constraints
        (edges) and see if the two positions are indeed ascending. 
        * To see if the given sequence is the only one, we need to make sure if there
        is an edge between any consequtive elements in the given sequence. Otherwise
        we can swap the two consequtive elements to create a new valid sequence. This
        can be clearly seen and proved by visualizing the topological sorted sequence
        with edges on it. This can be implemented while iterating the edges, if it
        connects two consequtive elements in the given sequence, we mark the previous
        element as true. After finish the iteration, if the number of marked elements
        is equal to n - 1(n is the total number of element in the given sequence),
        then it means that this condition is satisfied.
    https://discuss.leetcode.com/topic/65633/very-short-solution-with-explanation
    https://discuss.leetcode.com/topic/65961/simple-solution-one-pass-using-only-array-c-92ms-java-16ms
    O(V+E) time and O(V) space, much shorter code!
(3.5)Compute all topological sorts. The solution should always run in O(N!) time.
One way is to check if each possible solution is topological sort in linear time.
https://www.quora.com/Given-a-graph-how-to-compute-all-of-the-possible-topological-sort-outcomes
Another way is to do DFS traversal, starting from each node with 0 incoming degree,
which is hard to implement:
http://www.geeksforgeeks.org/all-topological-sorts-of-a-directed-acyclic-graph/

(4)Eulerian path.
(4.1)Definition: In graph theory, an Eulerian trail (or Eulerian path) is a trail
in a graph which visits every edge exactly once. Similarly, an Eulerian circuit or
Eulerian cycle is an Eulerian trail which starts and ends on the same vertex.
(4.2)A directed graph has an Eulerian trail if and only if at most one vertex has
(out-degree) − (in-degree) = 1(starting point), at most one vertex has (in-degree)
− (out-degree) = 1(finishing point), every other vertex has equal in-degree and out-degree,
and all of its vertices with nonzero degree belong to a single connected component
of the underlying undirected graph.


Problems:
(1)[Leetcode]Clone Graph, good practice for BFS and DFS. (Algorithms** and Implementations**)
(2)[Leetcode]Surrounded Regions. (Algorithms and Implementations*). For DFS, sometimes
we need to add some restrictions to prevent stack overflow.Remember BFS implementation
to this kind of problems.
(3)[Leetcode]Number of Islands. (Algorithms*)
(4)[Leetcode]Word Search. (Algorithm*) When the word is empty, returns true.
(5)[Leetcode]Word Search II. (Algorithm and Best Implementation*)
(6)[Leetcode]Word Ladder I(Algorithms and Implementations*). Remember the implementation
of Bidirectional BFS. endWord is counted as transformed word, so if it is not in the
wordList, we should return 0.
(7)[Leetcode]Word Ladder II(Algorithms and Implementations*). Remember the implementation
of finding all shortest paths using BFS. 
(8)[Leetcode]Restore IP Addresses(Implementation*). '012' is invalid while '0' is
valid.
(9)[Leetcode]Combination Sum(Implementation). What's the DP solution?
(10)[Leetcode]Combination Sum II(Algorithm*). DP solution? Remember the way of thinking
combination related problems!
(11)[Leetcode]Combination Sum III(Implementation*).
(12)[Leetcode]N Queens. (Algorithm*)
(13)[Leetcode]Generate Parentheses. (Algorithm). DP solution?
(14)[Leetcode]Sudoku Solver(Implementation). DFS with return boolean check.
(15)[Leetcode]Pacific Atlantic Water Flow.(Algorithm* and Implementation*) BFS solution
TBD.
(16)Topological sort:
    - [Leetcode]Course Schedule I and II(Algorithms* and Implementations*). Remember
    all of them!
(17)Eulerian path:
    - [Leetcode]Reconstruct Itinerary(Algorithms* and Implementations*). Remember
    the naive algorithm and implementation. I don't get how the better algorithm works
    yet, though its implementation is much simpler.
(18)[Leetcode]Remove Invalid Parentheses(Algorithms*). Remember the new way of DFS
and BFS using top-down approach. 



7. Permutations, Combinations and Subsets.
Knowledge:
(1)Factorial representation of Permutation: P(n,k) = n! / (n-k)! 
(2)Factorial representation of Combination: C(n,k) = n! / (k! * (n-k)!)
(3)(1 + X)^n = Sum(Cn,k * X^k), 0 <= k <= n
(4)C(n,k) = C(n-1, k-1) + C(n-1, k)
(5)Permutations, Combinations and Subsets can all be solved by standard DFS or iterative
solution based on induction. To remove duplicates, we can either use a hashtable or
sort the original array first and then compare the current number with the previous
one. Combinations and Subsets problems can also be solved using BitSet, but not recommended
as first trial.

Problems:
(1)[Leetcode]Permutations I and II (Multiple Algorithms**). Need to be careful of the
recursive solution for II.
(2)[Leetcode]Permutation Sequence(Best Algorithm and Implementation*)
(3)[Leetcode]Combinations(Algorithms*)
(4)[Leetcode]Subsets I and II(Multiple Algorithms**)
(5)[Leetcode]Letter combinations of a phone number(Iterative Algorithm*). Remember
the iterative algorithm!



8. Heap

Knowledge(mainly come from Robert's Algorithms):
(1)Priority queue is a abstract data type, like an interface in Java, that can be
implemented with different concrete data structures -- unordered array, ordered array
, linked list or heap. The performance of the basic operations like max and insert
varies in all those implmentations(See Robert's Algorithms for the comparison chart).
(2)Heap is a concrete data structure that is typically used to implement priority
queue. Usually heap refers to binary heap, but could also refer to d-ary heaps. In
concept, a binary heap is a complete binary tree. Each node in the tree is larger
than or equal to the keys in that node's two children. The heap operations require
traversing not only down but also up, so in practice, heap is usually implemented
as an array.
(3)Attributions of Heap(max-root):
    (3.1)The largest key in a heap-ordered binary tree is found at the root.
    (3.2)The height of a complete binary tree of size N is ⎣lg N⎦ .
(4)Operations on heap:
    (4.1)parent, leftChild, rightChild. Simple O(1) operations on the indices.
    (4.2)Size of array and size of heap is different!
    (4.3)exchange two nodes.
    (4.4)Bottom-up reheapify (swim/sift-up). O(lg N)
    (4.5)Top-down reheapify (sink/sift-down). O(lg N)
    (4.6)Insert. Add a new key, increase heap size, call 4.4. O(lg N)
    (4.7)Remove the maximum/minimum(root), and return the new root key. Exchange last
    key with the root key, decrease heap size, call 4.5 to sink the root key. O(lg
    N).
    (4.8)Build heap. Call insert(4.6) one by one. O(nlogn), but if we do it from right
    to left: to call sink(4.5) from the halfway of the array to the left, it runs
    in O(2n) = O(n) time.The proof is in Introduction to Algorithms. This can convert
    an unordered array to a heap. 
    (4.9)Heap sort(ascending order): (http://algs4.cs.princeton.edu/24pq/Heap.java.html)
        Build max heap(4.8)
        while (N > 1) {
            swap(root, last element of the heap);
            N--  // Decrease the heap size by 1.
            sink(root);
        }
(5)Indexed priority queue(Robert's Algorithms). Puting indices into a PQ insead of
the keys directly, and compare the nodes based on the key(not the index!). What is
swapped during reheapfiying is the content of the array(the indices). Therefore when
implementing it using a heap, besides the heap array, we also need a map of index
to the key, which is often implemented with another array since the index is usually
an integer. The operation 4.7 for this case usually returns the index. And besides
the typical PQ operations, there are change(int k, Item item) method that change the
key associated with index k to a new key, which requires a third array storing the
actual array index for each index of the key(another map). For typical heap PQ, it
usually takes the array index directly so no mapping is needed. An useful applciation
is also provided in the book: merging multiple sorted streams.
Source code: http://algs4.cs.princeton.edu/24pq/IndexMinPQ.java.html
Also note that if the input are known elements instead of streams, we can also use
divide and conquer to merge them, and the time complexity is similar but the space
complexity could be much lower. E.g. [Leetcode]merge k sorted lists.
(6)Java Implementation: class java.util.PriorityQueue. Doesn't permit null values.
It is essentially a min heap. Example usage:
        //Two arguments passed are capacity and comparator. In the following case,
        //the priority queue stores the elements of ListNode type, and one node is
        //larger than the other when its value is larger than that of the other node.
        //The following implementation of compare method is preferable to just return
        //node1.val - node2.val since the latter could have overflow problem
        PriorityQueue<ListNode> pq = new PriorityQueue<>(lists.length, new Comparator<ListNode>() {
            public int compare(ListNode node1, ListNode node2) {
                if (node1.val > node2.val) {
                    return 1;
                } else if (node1.val < node2.val) {
                    return -1;
                } else {
                    return 0;
                }
            }
        });
        //Use the following to create max heap:
        PriorityQueue<Integer> queue = new PriorityQueue<>(10, Collections.reverseOrder());
        //Collection.reverseOrder() returns a ReverseComparator that has a compare
        () method that returns the negation of the compareTo method result of the
        object.

Problems:
(1)[Leetcode]Merge K sorted lists(Algorithms*).
(2)[Leetcode]Kth largest element in an array. (Algorithms of heap solutions*)
(3)[Leetcode]Rearrange String k Distance Apart(Algorithms* and Implementations*).
The naive algorithm and greedy algorithm should all be mastered! Don't know how to
prove the correctness of greed algorithm yet. 


9. Sorting and Searching

Knowledge(mainly from Coding Manual and Robert's Algorithms):
(1)Source code for sortings is in Sortings.java.
(2)Insertion sort, bubble sort and selection sort. Although all of them run in O(n^2)
time using O(1) space, insertion sort is usually the most efficient(fastest, even
faster than other O(nlogn) sorting algorithms when the array is small), while bubble
sort is the least efficient. This can be seen from the source code, the number of
basic operations in each loop of bubble sort is simly larger than the other two. When
the input array is mostly or fully sorted, insertion sort can perform much less operations,
while selection sort still performs almost as many as usual. Selection sort generally
performs more comparisons than insertion sort, but less writes.
Also note that the first two algorithms are stable, while the selection sort is not.
Example: for [9, 3, 2, 9, 1], the first 9 will be swapped with 1, leading to a change
of relative order of the two 9s.
(3)Merge sort. O(nlogn) time. Needs auxiliary space. Can be implemented using top-down
or bottom-up approaches. The space usage can be reduced a bit by adding more array
copy operations and do in-place changes instead of returning a new array. The speed
can be further improved by using insertion sort instead of merge sort when the subarray
is small.
(4)Quick sort. Worst case O(n^2) time and on average O(nlogn) time. To make sure it
runs in O(nlogn), either the pivot is choosen randomly or the array is shuffled before
partitioning. Two partition schemes exist -- Lomuto(used in Introduction to Algorithms)
and Hoare(similiar to my implementation, which seems to be more popular, but not easy
to understand. Need to remember it).
As per Robert's Algorithms, the average performance of quick sort is usually better
than the other O(nlogn) sorting algorithms, due to fewer data movements and comparisons.
The speed can be further improved by using insertion sort instead of quick sort when
the subarray is small.
(5)Heap sort. The algorithm is in 8.3.9. O(nlogn) time and O(1) space, unstable. The
number of comparisons is simliar to quick sort, but the cache misses are much larger
than the other sorting algorithms, becasue the array entries are rarely compared with
nearby array entries(locality of reference is lower). Cache is always loaded in blocks
and each block contains data that are adjacent to each other. Thus quick sort still
outperforms heap sort most of the time.
(6)Linear time sorts.
    (6.1)Counting sort. It tries to put each input element directly to the destination
    according to the number of elements that are no greater than it, which is computed
    beforehand. <<Introduction to Algorithms>>
        * Counting sort is efficient if the range of input data is not significantly
        greater than the number of objects to be sorted. Consider the situation where
        the input sequence is between range 1 to 10K and the data is 10, 5, 10K, 5K.
        * It works as long as the input elements can be mapped to a range of integers.
        So even if the input elements are negative or characters, it could still work.
        * Counting sort is stable. Thus it can be used as a subroutine in radix sort.
    (6.2)Radix sort. This is useful when each of the input elements consists of several
    (preferably known and fixed) columns. In such case, this algorithm uses stable
    sort to sort from the least significant to the most significant column. E.g, if
    the input elements are d-digit integers:
    Radix-sort(A, d):
        for i = 1 to d {
            stable_sort(like counting sort) A on digit i;
        }
    If we do stable sort for each digit using linear sorts like counting sort, the
    radix sort runs in O(d(n+k)) time, or O(dn) since k is less than 10. However in
    practice radix can be easily outperformed by other sorting algorithms when d is
    larger than logn. Also radix sort requires more space and less flexible than the
    other in-place sorting algorithms. 
    https://www.quora.com/If-Radix-sort-has-a-better-time-complexity-why-is-quick-sort-preferred-both-in-APIs-and-in-terms-of-interviews
    Overall, radix sort is a stable sort.
(7)External sort to deal with big data and small memory.
http://faculty.simpson.edu/lydia.sinapova/www/cmsc250/LN250_Weiss/L17-ExternalSortEX2.htm
(8)Binary search. 
    (8.1)The goal is to find a certain element(or the largest element that is smaller
    than it, or the smallest element that is larger than it, etc)in a sorted array.
    (8.2)Cases to consider:
        * Valid case, including when the target element is on the edge.
        * Target element is within the range of the array but not contained in the array
        * Target element is out of the range of the array, either smaller than the
        minimum element in the array or greater than the maximum element in the array.
        * For above cases, don't forget the case when the input array has no or only
        one element.
    (8.3)Type of search problems and its implementations. General idea is to start
    with initial range of candidates [low, high], compare target with a[mid](or a
    [low], a[high] if necessary), then narrow down the candidates by half and search
    in the new range. Pay attention to how mid value is calculated since we want the
    range to keep shrinking to 1. For problems that the range can not be cut down
    to half(time is more than O(logn)), low or high can be increased or decreased
    gradually.
        (8.3.1)Traditional problem -- return the index of the element if found, otherwise
        return -1:
            int binarySearch(int[] a, int target) {
                int low = 0;
                int high = a.length - 1;
                int mid;
                while (low <= high) {
                    mid = low + (high - low)/ 2; //Avoid potential overflow,
                                                 //can also written as:
                                                 //low + ((high - low) >> 1)
                    if (target > a[mid]) {
                        low = mid + 1;
                    } else if (target < a[mid]) {
                        high = mid - 1;
                    } else {
                        return mid;
                    }
                return -1; // Error
            }

            int binarySearchRecursive(int[] a, int target, int low, int high) {
                if (low > high) return -1;// Error
                int mid = low + (high - low) / 2;
                if (target > a[mid]) {
                    return binarySearchRecursive(a, target, mid+ 1, high);
                } else if (target < a[mid]) {
                    return binarySearchRecursive(a, target, low, mid - 1);
                } else {
                    return mid;
                }
            }
        (8.3.2)Returns the index of first element that is greater than or equal to
        the target element. Returns n if all elements in the array of n are less than
        the target element.
                int firstGreaterEqual(int[] nums, int target) {
                    int low = 0;
                    int high = nums.length;
                    while (low < high) {
                        int mid = low + (high - low) / 2;
                        if (target > nums[mid]) {
                            low = mid + 1;
                        } else {
                            high = mid;
                        }
                    }
                    return low;
                }
        (8.3.3)Returns the index of last element that is less than or equal to the
        target element. Returns -1 if all elements in the array are greater than the
        target element.
                int lastLessEqual(int[] nums, int target) {
                    int low = -1;
                    int high = nums.length - 1;
                    while (low < high) {
                        int mid = high - (high - low) / 2;
                        if (target < nums[mid]) {
                            high = mid - 1;
                        } else {
                            low = mid;
                        }
                    }
                    return high;
                }
        When the target is within the range of the input array, returning low or high
        are all fine since they will be equal in the end, however when the target
        is not within the range, the end value of low is not equal to high!
        (8.3.4)Another way to deal with the above two problems is to intialize a variable
        at the begining to record the index of last found candidate. The rest is similar
        to the basic binary search and after the loop finishes, that variable should
        contain the final result. See EPI for the solutions to above problems.
        (8.3.5)Search in rotated sorted array. To search for the minium value, comparing
        the mid element with the highest element in the array is simpler than comparing
        it with the lowest one. Break the loop until low == high and return the final
        index. The minimum element always exists as long as the array is not empty.
        To search for the element in the array that is equal to the target, we first
        compare the mid element with the target and return if they are equal. Next
        we can either compare the mid element with the lowest or highest. It's better
        to compare with the highest too to be consistent. Then compare the target
        with the edge element according to different situations. The code is similar
        to 7.3.1.
        (8.3.6)Search a certain element that satisfies some condition. No explicit
        target value. The algorithm is usually to first check the middle value for
        a certain condition and use that condition to determine whether the next step
        is to go to the left half or the right half. The key is to determine what
        condition to use.

Problems:
Binary Search problems:
    (1)[Leetcode]Search Insert Position(Algorithms*). (8.3.2). If the
    target is in the array and there are more than one, then the returned index could
    be the id of any of those elements.
    (2)[Leetcode]Search for a Range(Algorithms*). (8.3.2) and (8.3.3)
    (3)[Leetcode]Sqrt(x). (Algorithm*). (8.3.2). Be careful about overflow!
    (4)[Leetcode]Search in rotated sorted array I and II(Algorithm**). (8.3.1)with
    changes. Remember the algorithm! (8.3.5)
    (5)[Leetcode]Find Minimum in Rotated Sorted Array I and II(Algorithm**). These
    problems return the min value rather than the id.(8.3.5)
    (6)[EPI]Search local minimum in partially sorted array(Algorithm).(8.3.6)
    Description is in CodingPractices/EPI/SearchLocalMinimum.java
    (7)[Leetcode]Median of two sorted arrays(Algorithm** and Implementation*).
    (8)[Leetcode]Search a 2d Matrix. (8.3.1)
    (9)[Leetcode]Search a 2d Matrix2.(Best algorithm*)
    (10)[Leetcode]First bad version(Implementation). (8.3.2 with slight change). When
    all of the versions are good, return whatever(0 works).
Sorting problems:
    (1)[Leetcode]Kth largest element in an array(Algorithm* and implementation* of quick
    select)
    (2)[Leetcode]Insert Interval(Algorithm* and Implementation**).
    (3)[Leetcode]Merge Intervals(Algorithm)
    (4)[Leetcode]Sort Colors(Algorithm**)
    (5)[Leetcode]Insertion Sort List(Best Implementation*)
    (6)[Leetcode]Sort List(Implementation*). Bottom-up merge sort on linked list.
    Very hard to write the code! Top-down approach is much easier and may probably
    be enough.


10. Bit Manipulation

Knowledge:
(1)Arithmetic(Signed) shift vs Logical(Unsigned) shift. Java: >>, <<(arithmetic),
>>>(logical). http://docs.oracle.com/javase/tutorial/java/nutsandbolts/op3.html
There is no '<<<' in Java since arithmetic shift left works the same as logical shift
left -- the bit next to MSB is left-shifted to replace MSB.
https://en.wikipedia.org/wiki/Bitwise_operation#Arithmetic_shift
(2)Implementation of several common bit operations(Java):
    boolean get(int num, int i) {// i is the zero-based index from the right.
        return ((num & (1 << i)) != 0);
    }

    int set(int num, int i) {//set the bit at index i in num to 1
        return num | (1 << i);
    }

    int clear(int num, int i) {//set the bit at index i in num to 0
        return num & (~(1 << i));
    }

    //Clear all bits from the most significant bit(leftmost bit) through i(inclusive):
    int clearBitsMSBthroughI(int num, int i) {
        return num & ((1 << i) - 1);
    }

    //Clear all bits from i through 0(inclusive)
    //-1 is a sequence of all 1s in the binary represenation
    int clearBitsithrough0(int num, int i) {
        return num & ((-1 << (i + 1)));
    }

    //Update the bit value at index i to be the value corresponding bitisl
    int updateBit(int num, int i, boolean bitisOne) {
        return bitisOne ? set(num, i) : clear(num, i);
    }
(3)Exclusive or has commutativity and associativity.([Leetcode]Single Number)
(4)Negation of an integer is just to take the 2's complement -- invert all the bits
and add one. This works for both positive and negative integer!
(5)Subtract 1 from positive integer and negative integer work the same!
(6)Find out the rightmost set bit: if diff = (10010)b, then diff & (-diff) is (00010)b,
which is the same as diff & ~(diff - 1). ([Leetcode]Single Number III)

Problems:
(1)[Leetcode]Gray Code(Algorithm**). Remember the algorithm.
(2)[Leetcode]Single Number(Algorithm*). Clarification of the description: Every element
appears twice except that one element appears only once. Remember the algorithm.
(3)[Leetcode]Single Number II(Algorithms**). Clarification of the description: Every element
appears three times except that one element appears less than three times. Remember
the algorithms. The algorithms can be extended.
(4)[Leetcode]Single Number III(Algorithm**).




11. Math
Knowledge:
(1)Pay attention to the following cases(here overflow also refers to the underflow
case):
    * The sum/diff/product of two numeric variables could overflow.
    * In the case of division( 5/4 = 1, -5/4 = -1(NOT -2)):
        ** The divisor is zero, return INT_MIN if the dividend is negative or INT_MAX
        if otherwise.
        ** The dividend is INT_MIN and the divisor is -1. The quotient will overflow.
        ** The dividend is INT_MIN and the divisor is 1. The quotient will not underflow,
        which is INT_MIN. But this case should be noticed.
    * Powers of zero. Zero to the zero power equals ONE. Zero to any positive powers
    equals ZERO. Zero to any negative powers is UNDEFINED.
    * Negation could overflow if the variable is MIN_VALUE.
(2)Handling overflows:
    * Use larger primitive types. E.g. Use Long for Int, Double for float.
    * Use unsigned primitive types.
(3)Best algorithm of multiplying big integers. See the Leetcode problem below.
(4)Best way of comparing the floating numbers is still check if the difference of
them is smaller than some value. The value of Double could be NaN(like the 0.0/0.0),
POSITIVE_INFINITY, NEGATIVE_INFNITY, +0, -0, which are not equal to each other(especially
+0 is not evaluated as equal to -0, for both equals() and compareTo()).

Another way of comparing them is to use BigDecimal, which might be more costly.
http://stackoverflow.com/questions/28972497/java-double-comparing-vs-string-comparing
http://blog.csdn.net/wcxiaoych/article/details/42806313.

The default implementation using equals, compareTo or just comparator have some rounding
errors, which could still work if the floating numbers are not that closed to each
other.

E.g. [Leetcode]Max Points on a Line.

(5) In y = kx + b, k is called 'slope', and b is called 'y-intercept'.

Problems:
(1)Pow(x, n). (Best algorithm* and Implementation). Remember the best algorithm
(2)Add Two Numbers.(Implementation)
(3)Divide Two Integers.(Algorithm* and Implementation*). Remember the algorithm.
(4)Multiply Strings. (Best Algorithm**). 
(5)Max Points on a Line. (Best Algorithm* and Implementation*). 




12. Dynamic Programming and Memoization

Knowledge:
(1)Difference between DP and Memoization. DP is usually bottom-up while memoization
is top-down. See more(including the advantages and disadvantages of each): 
http://stackoverflow.com/questions/6184869/what-is-difference-between-memoization-and-dynamic-programming
(2)Memoization can run faster than DP when not all of the sub problems need to be
computed. However as a sacrifice, it has higher memory usage due to the recursion
stack, and the size of cache cannot be reduced like that of DP, which could be reduced
to one dimension sometimes(like in the following Longest Common Subsequence problem).
-- [Leetcode]Scramble String, Interleaving String.
(3)Thinking steps:
    * If the problem want to find out the longest/maximum value, or a searching result,
    it is often a sign of optimization problem which can potentially be tackle using
    DP/Memoization. Search algorithms like DFS/BFS can also be used, but sometimes
    the search space could be extremely large, making them not preferable approaches.
    Greedy algorithm can solve them too, which is often hard to come up with and should
    be used as a last resort. For some problems, divide and conquer can also be used
    to solve them. -- [Leetcode]Maximum Subarray.
    * Break the original problem into subproblems and then create the recursive formulas.
    DP/memoization works well when the subproblems overlap, otherwise simple recursion
    works better. Sometimes instead of breaking the original problem, we can break
    a variation of it whose solution can easily lead to the solution of the original
    problem. Ways of breaking the problem:
        ** For sequences, consider s[l-1] when solving the problem for s[l], which
        stores the result of sequence with length l. (It is often preferable to
        use length as index of cache rather than the index of sequences, since the
        starting elements in the cache ususally have length zero, and negative index
        of sequences. The index of cache should be non-negative.) This way is commonly
        used when the input has multiple sequences. --[Leetcode]Longest Common Subsequence,
        [Leetcode]Edit Distance.
        ** For sequences, consider s[i-1] when solving the problem for s[i], which
        contains the result of sequence starting or ending with element at index
        i. -- [Leetcode]Maximum Subarray.
        ** Sometimes it is good to have a final process to conquer the results of
        all the subproblems, which could help design subproblems that are easier to
        solve in less time. -- [Leetcode]Best Time to Buy And Sell Stock, generaliazation
        DP solution.
        ** If the cache is multi-dimensional, like d[m][l], when coming up with the
        recursive formula, try considering its relation with all possible subproblems,
        like d[m-1][l], d[m][l-1], or a combination of them. -- [Lintcode]Maximum
        Subarray II.
        ** Sometimes multi-dimentional cache in the recursive formula can be reduced
        to one-dimentional by fixing the other dimention(usually that requrires another
        iteration to get the final result). -- [Leetcode]Palindrome Partitioning II,
        Maximum Subarray II.
        ** Sometimes need to maintain multiple db arrays, e.g. Let d[i][1] denote
        select the current element and d[i][0] denote not select.
        -- [Leetcode]Maximum product subarray, house robber I.

    Think about the order of indices first before writing down the formulas.
    Don't forget to write down the range of valid indices of the recursive formulas
    (and the target!).

    * Implement the solution using DP/memoization. 
        ** If using DP and the path needs not to be returned, consider reducing the
        size of cache. For many problems the size can be reduced to one or two 1D
        arrays or even a few variables. A swap of array pointers is often used at
        the end of each iteration if two 1D arrays are used. Previous visited element
        of the current array can be stored lazily to reduce two arrays to only one.--
        [Leetcode]Edit Distance.
        ** Think about the starting values carefully, especially those out of the
        range of valid cache elements. Note that the recursive formulas assume that
        the previous state is valid. So when coding be sure to check the cache values
        that are next to the starting values. Better to do this with a DP full matrix
        and check the edge computed values that are adjacent to intialized values
        carefully. They could need special handling sometimes!
        ** The max/min in the recursive formulas can often be computed on the fly
        instead of using a separate loop. This can often reduce the degree of time
        complexity.
        ** Prefer using boolean expression to if-else statements to implement the
        recursive formulas.--[Leetcode] Interleaving String.
    * When the path needs to be returned, we have following options:
        ** Cache the optimal path for each subproblem and return the result in O(1) time.
        However the downside is it is very costly in space.
        ** If the cache for the optimal results is in 2D, we can reconstruct the path from
        the final problem by iterating the cache, which can be done in linear time.
        ** If the cache for the optimal results is already reduced to 1D, then another
        2D array should be created to store the index/direction of subproblems. Iterating
        this new array like above can reconstruct the path in linear time too.
    The above options also apply to memoization.

Problems:
(1)[Lintcode]Longest Common Subsequence(Algorithms and Implementations*). Very good
introductory problem.
(2)[Leetcode]Maximum Subarray(Algorithms*)
(3)[Lintcode]Maximum Subarray II(Algorithm** and Implementation*)
(4)[Leetcode]Longest Increasing Subsequence(Best Algorithm**)
(5)[Leetcode]Regular Expression Matching(Algorithm* and Implementation*).
Pay attention to the rolling arrays!
(6)[Leetcode]Wildcard Matching(Algorithms*).
(7)[Leetcode]Edit Distance(Algorithm**).
(8)[Leetcode]Scramble String(Algorithms*).
(9)[Leetcode]Interleaving String(Algorithms*).
(10)[Leetcode]Palindrome Partitioning II(Algorithms** and Implementations*).
(11)[Leetcode]Word Break(Algorithms). Clarification: It is okay for the substring
in s to appear multiple times in dict. E.g. wordDict("leetcodeleet", ["leet", "code"])
should also returns true. The order in s doesn't matter. and "leetleet" should return
true too.
The solution can be further improved by using Trie, but it can be put aside for now.
(12)[Leetcode]Word Break II(Implementation**). Good example of using DFS memoization/DP
to return all solutions instead of just a value. If you have to copy array of strings,
sometimes just store the concatenation of them makes writing the code much easier.
Remember this implementation.
(13)[Leetcode]Maximum Product Subarray(Algorithm*).
(14)[Leetcode]Unique Paths I and II.
(15)[Leetcode]Unique Binary Search Trees.
(16)[Leetcode]Unique Binary Search Trees II.(Algorithms). Best algorithm I think is
this one: https://discuss.leetcode.com/topic/6711/share-a-c-dp-solution-with-o-1-space
This problem can also be solved by recursive approach with or without cache. Remember
the first approach.
(17)[Leetcode]Triangle(Best Algorithm*).
(18)[Leetcode]Combination Sum IV(Best Algorithm*)
(19)[Leetcode]House Robber(Multiple Algorithms*). Compare the solution with the one
for "Best Time to Buy and Sell Stock with Cooldown". Remember how to deal with max
{d[j], 0 <= j < i - k} where i is the current index.
(20)[Leetcode]House Robber II(Algorithm*)
(21)[Leetcode]Decode ways(Algorithm*). Be careful about the intial value!


13. Other Concepts and special problems, including greedy problems.
(1)P, NP, NP-Complete, NP-Hard.
http://stackoverflow.com/questions/1857244/what-are-the-differences-between-np-np-complete-and-np-hard
(2)Best Time to Buy and Sell Stock problems:
    (2.1)[Leetcode]Best Time to Buy and Sell Stock I and II(Algorithms).
    (2.2)[Leetcode]Best Time to Buy and Sell Stock III(Multiple Algorithms**). 
    (2.3)[Leetcode]Best Time to Buy and Sell Stock with Cooldown(Algorithm** and Implementation**)
(3)Use graphs to see the essence!
    (3.1)[Leetcode]Gas Station(Best Algorithm* and Implementation*).
(4)Initialize first and then fix one by one to satisfy certain conditions -- a typical
greedy algorithm!
    (4.1)[Leetcode]Candy(Algorithms* and Implementation of best algorithm**)
(5)Two pointers.(TBD)
(6)Parentheses related problems. 
    Two ways of thinking: 
    * Using a stack and iterate a string, whenever you encounter a ')', check if the
    top of the stack is '(', if so, pop it, otherwise push ')'. 
    * Compare the numbers of '(' and ')' encountered so far and compare them. For
    any valid parentheses, those number should be equal. Using counters of parentheses
    can easily calculate the length of formed parentheses. 
    (6.1)[Leetcode]Valid Parentheses.
    (6.2)[Leetcode]Longest Valid Parentheses(see previous chapter).
    (6.3)[Leetcode]Generate Parentheses(see previous chapter)
    (6.4)[Leetcode]Remove Invalid Parentheses(see previous chapter). One pass iteration
    we can get the minimum number of parenthese we should remove to make it valid.
    If just need to return one solution, two passes + stack is enough.
(7)File related.
    (7.1)Read N Characters Given Read4 I(Algorithm) and II(Implementation*)
(8)Arithmetic expression evaluation.
    (8.1)[Leetcode]Basic Calculator II(Best Algorithm* and Implementation, see previous).
    Remember the best solution(very fundamental!). Also remember the implemenation
    logic of getting each integers from the string without using Integer.parseInt
    (string). 
    (8.2)[Leetcode]Expression Add Operators(Algorithm* and Implementation*, see previous).
    Remember the best backtracking logic and implementation.
    (8.3)[Leetcode]Basic Calculator I(Algorithms* and Implementations*, see previous).
    (8.4)[Leetcode]Different Ways to Add Parentheses(Algorithm*, see previous).Remember
    the way of enumerating different order of calculating an arithmetic expression.
    (8.5)Basic calculator when the operators have * and / ?


14. Data Structure Design.
Kownledge:
(1)If multiple lists are involved in the data structure to be designed, make sure
they are synced if there are removal operations. One typical way is to maintain pointer
from each node to the corresponding one. If the removal operation could happen on
both lists, then the pointers must be from two directions.
(2)Balanced BST and heap have similar performance. Always consider both of them together!
Note: removal in balanced BST takes O(logn) while in heap is O(n).
Getting the max/min in balanced BST takes O(logn) while in heap is O(1).
(3)About iterator. hasNext() returns true if next() would return an emement. The correct
usage is always calling hasNext() before next(), however the implementation should
not use this as an assumption! hasNext() should never change the state of the iterator,
and next() should always return a valid next element even if it is called without
calling hasNext() first. It could throw an exception if there is no more element.
Ideally the iterator should not have a copy of all the elements being iterated on.
It should mainly rely on other existing iterators to do the work.
(4)If the problem uses some existing data structures, be sure to understand what they
essencially are first! Some existing data structures are like graphs, which indicate
a dfs/bfs could be used in the problem

Problems:
(1)Max Stack. Implement a Max Stack that supports peekMax() and popMax(), both of
which should run in O(1) time.
My solution: Maintain two double-linked lists, one is sorted, the other serves as
a stack. The corresponding nodes in two lists have pointers pointing to each other,
so that when popMax is called on the sorted list, the corresponding one in the stack
is removed, and when pop is called on the stack, the corresponding one in the sorted
list is removed. And since the two lists are double-linked list, the pop operations
run in O(1) time. peekMax is also O(1). For push, one element is inserted in the stack,
and a copy of it is inserted in the sorted array in O(n) time.
(2)[Leetcode]Find Median from Data Stream(Algorithm* and Best Implementation*).
(3)[Leetcode]Sliding Window Median(Algorithms* and Best Implementation*). Remember
two ways of implementing multi-sets!
(4)Iterator related:
    - [Leetcode]Flatten Nested List Iterator(Algorithms*)


Summary of algorithms that are frequently used:
1. Caching. If there are multiple arrays involved, caching could be used on any one
of them!
2. Recursive thinking. Break the original problem into sub-problems. Try solving with
recursive approach first --- can be broken down into two or more parts, or based on
the result of first n-1 elements. If there are repetitions among sub-problems, consider
caching and DP, otherwise, divide(two or more parts) and conquer.
* Don't always try finding the breaking point in O(1) time. It might be easier to
find it in O(n) time first(top-down approach).
3. Greedy thinking(TBD)
4. If the problem has the time complexity of (nlogn), consider the following possible
cases:
    (1)Sorting
    (2)Binary search, either recursively and then iterate(divide and conquer), or
    doing it in each iteration.
    (3)Constructing/using a balanced BST(like Java TreeMap) in each iteration.
    (4)Constructing/using a heap in each iteration.



* Sometimes when getting stuck, rethink what the problem asks and try coming up with
a different idea. Be sure to think clearly what exactly gets stuck and can explain
it.
* Sometimes not understanding a concept/representation well is the cause of getting
stuck.
* Don't stop persuing a thought too quickly!
* Try guessing the possible time complexity could sometimes give a hint(like nlogn).






Implementation Utils:
* Sorting an array:
    (1) Java:
            int[] nums;
            Arrays.sort(nums);//In place, stable, O(nlogn) time.

            //Sort 2d array:
            //sumAndIds = {{5, 8}, {1, 2, 4}, {4, 5}}
            //After sorted: {{1, 2, 4}, {4, 5}, {5, 8}}
            Arrays.sort(sumAndIds, new Comparator<int[]>() {
                    @Override
                    public int compare(int[] o1, int[] o2) {
                        return Integer.compare(o1[0], o2[0]);
                    }
            });

* Sorting an list:
    (1) Java: List<Airport> dests = new ArrayList<>();
              dests.sort(new Comparator<Airport>() {
                @Override
                public int compare(Airport a1, Airport a2) {
                    return a1.name.compareTo(a2.name);
                }
              });

* Copying an array to a new array:
    (1) Java:
        (1.1)System.arraycopy():
            int[] arr = {1,2,3,4,5};
            int[] copied = new int[10];
            System.arraycopy(arr, 0, copied, 1, 5);//5 is the length to copy
            System.out.println(Arrays.toString(copied));

        Output:
            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
            [0, 1, 2, 3, 4, 5, 0, 0, 0, 0]

        (1.2)Arrays.copyOf() returns a copy of original array:
            int[] copied = Arrays.copyOf(arr, 10); //10 the the length of the new array
            System.out.println(Arrays.toString(copied));
            copied = Arrays.copyOf(arr, 3);
            System.out.println(Arrays.toString(copied));

        Output:
            [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]
            [1, 2, 3]


* Max and min Int
    (1) Java:
            Integer.MAX_VALUE;
            Integer.MIN_VALUE;

* Absolute value:
    (1) Java:
            int absDiff = Math.abs(4-5);

* Comparison of two numerical values:
    (1) Java:
            int maxOfTwo = Math.max(5, 4);
            int minOfTwo = Math.min(5, 4);

* Find the maximum/minimum in an array as well as the index:
    (1) Java:
        input: int[] height
        int highestPos = 0;
        int result = 0;
        for (int i = 0; i < height.length; ++i) {
            highestPos = (height[i] > height[highestPos]) ? i : highestPos;
        }

* Reverse a list:
    (1) Java: in place.
        java.util.Collections.reverse(List<?> list).

* Reverse a string:
    (1) Java: 
        //In place reverse!
        String reversed = new StringBuilder(original).reverse().toString()


* Convert String to Int:
    (1) Java:
            String number = "10";
            int result = Integer.parseInt(number);
            Integer result2 = Integer.valueOf(number);//if number is of int type,
            // this can also convert it to its Integer class

* Count the occurence of each character in a string:
    (1) Java:
            String t = "aerwerrsdf";
            Map<Character, Integer> TcharCounts = new HashMap<>();
            for (int i = 0; i < t.length(); ++i) {
                //getOrDefault is introduced since Java 8
                int curCount = TcharCounts.getOrDefault(t.charAt(i), 0);
                TcharCounts.put(t.charAt(i), curCount + 1);
            }

* Substring:
    (1) Java (public String substring(int beginIndex,
               int endIndex) ), beginIndex is inclusive and endIndex is exclusive
            "hamburger".substring(4, 8) returns "urge"
            "smiles".substring(1, 5) returns "mile"

* Find the index of a character in a string:
    (1) Java:
            String str1 = "allen chin is a hero";
            int pos1 = str1.indexOf('a'); // 0
            int pos2 = str1.indexOf('a', 3); // 14
        
* Concatinating strings and add delimiters between them:
    (1) Java 8: public static String join(CharSequence delimiter,
                          Iterable<? extends CharSequence> elements)
            List<String> strings = new LinkedList<>();
            strings.add("Java");strings.add("is");
            strings.add("cool");
            String message = String.join(" ", strings);
            //message returned is: "Java is cool"
            //This essentially iterate the input collection and append each element
            //to a string builder with delimiter in between. And at last convert the
            //string builder to string by calling sb.toString().

* Initialization of multiple variables:
    (1) Java supports this, which can also be used in for-loop
        int a1 = 3, a2 = 5, a3 = 7;

* Switch syntax:
    (1) Java:
        public String getTypeOfDayWithSwitchStatement(String dayOfWeekArg) {
         String typeOfDay;
         switch (dayOfWeekArg) {
             case "Monday":
                 typeOfDay = "Start of work week";
                 break;
             case "Tuesday":
             case "Wednesday":
             case "Thursday":
                 typeOfDay = "Midweek";
                 break;
             case "Friday":
                 typeOfDay = "End of work week";
                 break;
             case "Saturday":
             case "Sunday":
                 typeOfDay = "Weekend";
                 break;
             default:
                 throw new IllegalArgumentException("Invalid day of the week: " +
                 dayOfWeekArg);
         }
         return typeOfDay;
        }

* Conversion between primitive types and Binary Numeric Promotion

* Fastest way to return a list view of any number of elements:
    (1) Java:
         List<String> stooges = Arrays.asList("Larry", "Moe", "Curly");
         Note that the returned list is backed by the original array, not a copy,
         so modifying the original array will change the list!

* Initialize elements of an array with same values:
    (1) Java:
        boolean[] validCols = new boolean[n];
        Arrays.fill(validCols, true);
        //Initialize array list with null values:
        List<String> strs = new ArrayList<>(Collections.nCopies(10, null));

* Iterating and modifying a list:
    (1) Java:
        List<Integer> l1 = new ArrayList<>();
        iter = l1.listIterator();
        while (iter.hasNext()) {
            int id = iter.nextIndex();
            int cur = iter.next();
            if (cur == 4) {
                iter.remove();
            }
            System.out.println(id + ": " + cur);
        }

* Convert list to array:
    (1) Java:
        List<String> stockList = new ArrayList<String>();
        stockList.add("stock1");
        stockList.add("stock2");

        String[] stockArr = stockList.toArray(new String[0]);


