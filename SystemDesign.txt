Concepts.

CS75 video:

1. Web hosting service:
A web hosting service is a type of Internet hosting service that allows individuals
and organizations to make their website accessible via the World Wide Web. Web hosts
are companies that provide space on a server owned or leased for use by clients, as
well as providing Internet connectivity, typically in a data center.
Example: Bluehost, Dreamhost, Go Daddy, Host Gator, pair Networks.

2. Different types of web hosting service:
Shared, dedicated, VPS, Cloud.
https://hostingfacts.com/different-types-of-web-hosting/.

3. Vertical scaling:
Better hardware, like SSD.

4. Horizontal scaling:

5. Load balacing:
The DNS server can return the ip of load balancer instead of a server, and let the
load balancer decide which server the request should be sent to.
Load balancing strategies:
(1) Based on load of the server(how busy it is, the cpu usage).
(2) Store different types of files on different servers, and use the suffix of url
to discreminate them. 
(3) Round robin. Example: BIND(the most widely used Domain Name System (DNS) software
on the Internet) uses this strategy to resolve a host name --- same host name, but
different ip each time. The drawback of this strategy is that one or few server could
always receive requests that require most computation resource, making them much busier
than the rest. Another thing that can show it is a bad strategy is DNS caching, which
exists on the user's computer(maintained by the OS and browser). This caching is a
map of host name and ip address that will expire(clear) after a certain amount of
time(TTL). It is only used for speeding up the response time 
(https://www.lifewire.com/introduction-to-domain-name-system-817512). So if an user
keeps doing expensive work, it will always be done on the same server during TTL and
that server will be always busy. Therefore instead of relying on the DNS server to
do the load balancing, it is better to let the DNS server return the ip of the load
balancer.

Server-side sessions(http://stackoverflow.com/questions/3804209/what-are-sessions-how-do-they-work)
could cause problems for load balancing, because one session for a user is only stored
on one server. Solution: store all the sessions on a dedicated session server, or
the load balancer itself, which can be accessed by all servers. However what if the
server is down?
We could try using RAID to achieve data redundancy to some degree, but this is still
not a good solution, as it is possible that the whole server is down. A better way
to deal with it is to use multiple servers, which requires some syncing process.
Sticky session can also be a solution here, which can be implemented by storing an
id in the user's cookie and let LB to remember the mapping of that id to the ip of
the server the session belongs to.

Load Balancer choices:
Software:
ELB(AWS Elastic Load Balancing), HAProxy, LVS(Linux Virtual Server, http://www.linuxvirtualserver.org/whatis.html)
Hardware:
Barracuda, Cisco, Citrix, F5..


6. Caching.
(1) File based caching. Storeing a new file(html file) when new data is entered, like
what is done by Craigslist. The upside of this approach is that the html file doesn't
have to be regenerated everytime it's visited. The downside of it is due to the redundancy,
it is hard to change the common style of the pages. And it could use too much space.
(2) MySQL caching.
query_cache_type = 1 is enough to enable it. Used for cache the query result.
(3) Memcached
Cache data and objects in the RAM. Use LRU to purge old data when it is full.

7. Database replication
(1)Master-slave.
As the master-slave replication is a one-way replication (from master to slave),only
the master database is used for the write operations, while read operations may
be spread on multiple slave databases(and the master too).
Upside: data replication due to the several backup slaves. Load balancing read to
the slaves so that it can process large amount of traffic and scale out easily.
Downside: single-point-failure of the master db.
(2)Master-master.
Upside: 
* If one master fails, other masters continue to update the database.
* Masters can be located in several physical sites, i.e. distributed across the network.
Downside:
Very hard to preserve absolute consistency. 
http://stackoverflow.com/questions/21196000/mysql-master-master-data-replication-consistency

How to do the failover?? What does the consistency here mean?

8. Example 1: Load Balancing + Replication
(1)Load Balancer and MySQL master are the single points of failures.
Multiple load balancers: active - active or active - passive.
One needs to send its heartbeats(packages) every period of time to another.
http://serverfault.com/questions/388543/load-balancing-active-active-config-and-dynamic-server-addition

9. Example 2: with partitioning.

10. Security.
Open tcp port 80(http) and tcp port 443(https) for the traffic coming into the LBs.
Opening tcp port 80 for the inside traffic after first layer of LB can save putting
SSL certificate on all of the web servers.
Open tcp port 3306(MySQL db server default)

Knowledge:

* Computer Protocols- TCP/IP, POP, SMTP, HTTP, FTP and More
http://vlaurie.com/computers2/Articles/protocol.htm


* TCP vs UDP
https://www.howtogeek.com/190014/htg-explains-what-is-the-difference-between-tcp-and-udp/
UDP is less reliable but much faster, so it is preferable for transmitting time-critical
data, like live video stream and online game data.


* Cookies: Http Cookies and third-party cookies.
Drawbacks of cookies:https://en.wikipedia.org/wiki/HTTP_cookie#Drawbacks_of_cookies


* Three ways of managing sessions:
https://www.youtube.com/watch?v=32UGARg8AzU
Cookies
URL rewriting, Hidden fields
https://www.youtube.com/watch?v=xGAVFsLfn2w
https://www.youtube.com/watch?v=Pv3FST7OcvQ


* RAID(Redundant array of inexpensive disks):
It is a data storage virtualization technology that combines multiple physical disk
drive components into a single logical unit for the purposes of data redundancy,
performance improvement, or both.

RAID0: Uses data striping(technique of segmenting logically sequential data, such
as a file, so that consecutive segments are stored on different physical storage
devices) to perform concurrent read and write, so that the performance could be improved
by the number of disks. No data redundancy involved.

RAID1: Uses data mirroring to implement redundancy. Typically two idendical hard drives.
Write throughput is always slower because every drive must be updated, and the slowest
drive limits the write performance. 

RAID10: A combination of above.

* CAP theorem:
It is impossible for a distributed computer system to simultaneously provide more
than two out of three of the following guarantees:
Consistency, Availability, Partition Tolerance.
CAP is frequently misunderstood as if one had to choose to abandon one of the three
guarantees at all times. In fact, the choice is really between consistency and availability
for when a partition happens only; at all other times, no trade-off has to be made.
https://en.wikipedia.org/wiki/CAP_theorem
Strictly, most of the systems are not CAP-available if P happens. What this theorem
really says is that when P happens, you need to make a trade-off between C and A.
But you can never achieve 100% for both. E.g., if master-slaves is used for each shard,
and if read and write are performed on master, then strong consistency can be guaranteed,
but the level of availability is low when P happens between the router and the master.
We can change it by allowing read on slaves, which makes it no longer CAP-consistent
and increases the level of availability, but it is still not 100% available since
the write request could fail in such case.
https://martin.kleppmann.com/2015/05/11/please-stop-calling-databases-cp-or-ap.html

* Eventual Consistency, Strong Eventual Consistency, Strong Consistency
http://stackoverflow.com/questions/29381442/eventual-consistency-vs-strong-eventual-consistency-vs-strong-consistency
Another good article on eventual consistency and strong consistency:
https://cloud.google.com/datastore/docs/articles/balancing-strong-and-eventual-consistency-with-google-cloud-datastore/#h.w3kz4fze562t
As I understand it, strong eventual consistency uses CRDT to avoid conficts and thus
the data could be consistent after some time without resolving conficts before propagating
the update.
Tradeoff between consistency and latency:
http://cs-www.cs.yale.edu/homes/dna/papers/abadi-pacelc.pdf
Saved as CAP_tradeoff.pdf

* ACID transaction:
Atomicity. In a transaction involving two or more discrete pieces of information,
either all of the pieces are committed or none are.

Consistency. A transaction either creates a new and valid state of data, or, if
any failure occurs, returns all data to its state before the transaction was started.

Isolation. A transaction in process and not yet committed must remain isolated
from any other transaction.

Durability. Committed data is saved by the system such that, even in the event of
a failure and system restart, the data is available in its correct state.

* Database index:
http://www.programmerinterview.com/index.php/database-sql/what-is-an-index/
Typically database index is a datastructure like B tree(non-binary self-balancing
tree)

* Database normalization and denormalization:
https://www.essentialsql.com/get-ready-to-learn-sql-database-normalization-explained-in-simple-english/
http://www.vertabelo.com/blog/technical-articles/denormalization-when-why-and-how

* Ways of improving database query performance:
1. Optimizing the query itself, add caching.
2. Indexing.
3. Denormalization.

* Database partitioning.
https://en.wikipedia.org/wiki/Partition_(database)
Horizontal partitioning, or sharding in the distributed setting.
Vertical partitioning


* DBMS types:
https://www.youtube.com/watch?v=jSXxrTNZwXA
Relational, Use SQL: MySQL
Object-oriented, Use OQL: ObjectDB.
NoSQL:
Good introduction video: https://www.youtube.com/watch?v=qI_g07C_Q5I
Hard to define, usually has characteristics:
Non-relational, cluster-friendly, schema-less, open-source.
Types:
Key-value: Redis(CP?), Memcached, Oracle NoSQL database.
Document: MongoDB(CP)
Column: HBase(CP), Cassandra(AP)
Graph: Neo4j(CP)

	** Redis
	Introduction and Data Model: https://redis.io/topics/introduction
	Persistence: https://redis.io/topics/persistence
				 http://oldblog.antirez.com/post/redis-persistence-demystified.html
	Cluster and sharding: https://redis.io/topics/partitioning
			 https://redis.io/topics/cluster-tutorial
	vs Memcached, and why use Redis:
	http://stackoverflow.com/questions/7888880/what-is-redis-and-what-do-i-use-it-for

	** MongoDB
	Introduction and Data Model: https://www.youtube.com/watch?v=pWbMrx5rVBE
	Sharding: https://docs.mongodb.com/manual/sharding/
	Architecture: https://www.mongodb.com/presentations/webinar-everything-you-need-know-about-sharding?jmp=docs&_ga=1.78388884.1635526347.1487659117

	** HBase
	Introduction and Data Model: http://hbase.apache.org/0.94/book/datamodel.html
	Data Model and Architecture:  https://www.edureka.co/blog/hbase-architecture/

* SQL vs NoSQL
1. Consistency: 
SQL: Strong Consistency
NoSQL: Trade consistency for availability and partition tolerance, usually eventual
consistency. But still can achieve strong consistency.

#### NoSQL flavors  
##### Key-value 
* Suitable use cases 
	- **Storing session information**: Generally, every web session is unique and is assigned a unique sessionid value. Applications that store the sessionid on disk or in a RDBMS will greatly benefit from moving to a key-value store, since everything about the session can be stored by a single PUT request or retrieved using GET. This single-request operation makes it very fast, as everything about the session is stored in a single object. Solutions such as Memcached are used by many web applications, and Riak can be used when availability is important
	- **User profiles, Preferences**: Almost every user has a unique userId, username, or some other attributes, as well as preferences such as language, color, timezone, which products the user has access to, and so on. This can all be put into an object, so getting preferences of a user takes a single GET operation. Similarly, product profiles can be stored. 
	- **Shopping Cart Data**: E-commerce websites have shopping carts tied to the user. As we want the shopping carts to be available all the time, across browsers, machines, and sessions, all the shopping information can be put into value where the key is the userid. A riak cluster would be best suited for these kinds of applications. 

* When not to use 
	* **Relationships among Data**: If you need to have relationships between different sets of data, or correlate teh data between different sets of key, key-value stores are not the best solution to use, even though some key-value stores provide link-walking features. 
	* **Multioperation transactions**: If you're saving multiple keys and there is a failure to save any of them, and you want to revert or roll back the rest of the operations, key-value stores are not the best solution to be used.
	* **Query by data**: If you need to search the keys based on something found in the value part of the key-value pairs, then key-value stores are not going to perform well for you. This is no way to inspect the value on the database side, with the exception of some products like Riak Search or indexing engines like Lucene. 
	* **Operations by sets**: Since operations are limited to one key at a time, there is no way to operate upon multiple keys at the same time. If you need to operate upon multiple keys, you have to handle this from the client side. 

##### Document 
* Suitable use cases 
	- **Event logging**: Applications have different event logging needs; within the enterprise, there are many different applications that want to log events. Document databases can store all these different types of events and can act as a central data store for event storage. This is especially true when the type of data being captured by the events keeps changing. Events can be sharded by the name of the application where the event originated or by the type of event such as order_processed or customer_logged. 
	- **Content Management Systems, Blogging Platforms**: Since document databases have no predefined schemas and usually uderstand JSON documents, they work well in content management systems or applications for publishing websites, managing user comments, user registrations, profiles, web-facing documents. 
	- **Web Analytics or Real-Time Analytics**: Document databases can store data for real-time analytics; since parts of the document can be updated, it's very easy to store page views or unique visitors, and new metrics can be easily added without schema changes. 
	- **E-Commerce Applications**: E-commerce applications often need to have flexible schema for products and orders, as well as the ability to evolve their data models without expensive database refactoring or data migration. 

* When not to use 
	- **Complex Transactions Spanning Different Operations**: If you need to have atomic cross-document operations, then document databases may not be for you. However, there are some document databases that do support these kinds of operations, such as RavenDB. 
	- **Queries against Varying Aggregate Structure**: Flexible schema means that the database does not enforce any restrictions on the schema. Data is saved in the form of application entities. If you need to query these entities ad hoc, your queries will be changing (in RDBMS terms, this would mean that as you join criteria between tables, the tables to join keep changing). Since the data is saved as an aggregate, if the design of the aggregate is constantly changing, you need to save the aggregates at the lowest level of granularity-basically, you need to normalize the data. In this scenario, document databases may not work. 

##### Column-Family 
* Suitable use cases 
	- **Event Logging**: Column-family databases with their ability to store any data structures are a great choice to store event information, such as application state or errors encountered by the application. Within the enterprise, all applications can write their events to Cassandra with their own columns and the row key of the form appname:timestamp. Since we can scale writes, Cassandra would work ideally for an event logging system. 
	- **Content Management Systems, Blogging Platforms**: Using column-families, you can store blog entries with tags, categories, links, and trackbacks in different columns. Comments can be either stored in the same row or moved to a different keyspace; similarly, blog users and the actual blogs can be put into different column families. 
	- **Counters**: Often, in web applications you need to count and categorize visitors of a page to calculate analytics, you can use the CounterColumnType during creation of a column family. 
	- **Expiring usage**: You may provide demo to users, or may want to show ad banners on a website for a specific time. You can do this by using expiring columns: Cassandra allows you to have columns which, after a given time, are deleted automatically. This time is known as TTL and is defined in seconds. The column is deleted after the TTL has elapsed; when the column does not exist, the access can be revoked or the banner can be removed.

* When not to use 
	- **ACID transactions for writes and reads**
	- **Database to aggregate the data using queries (such as SUM or AVG)**: you have to do this on the client side using data retrieved by the client from all the rows. 
	- **Early prototypes or initial tech spikes**: During the early stages, we are not sure how the query patterns may change, and as the query patterns change, we have to change the column family design. This causes friction for the product innovation team and slows down developer productivity. RDBMS impose high cost on schema change, which is traded off for a low cost of query change; in Cassandra, the cost may be higher for query change as compared to schema change. 

##### Graph 
* Suitable use cases 
	- **Connected data**: 
		+ Social networks are where graph databases can be deployed and used very effectively. These social graphs don't have to be only of the friend kind; for example, they can represent employees, their knowledge, and where they worked with other employees on different projects. Any link-rich domain is well-suited for graph databases. 
	    + If you have relationships between domain entities from different domains (such as social, spatial, commerce) in a single database, you can make these relationships more valuable by providing the ability to traverse across domains. 
	- **Routing, Dispatch, and Location-Based Services**: Every location or address that has a delivery is node, and all the nodes where the delivery has to be made by the delivery person can be modeled as a graph nodes. Relationships between nodes can have the property of distance, thus allowing you to deliver the goods in an efficient manner. Distance and location properties can also be used in graphs of places of interest, so that your application can provide recommendations of good restaurants or entertainment options nearby. You can also create nodes for your points of sales, such as bookstores or restaurants, and notify the users when they are close to any of the nodes to provide location-based services. 
	- **Recommendation Engines**: 
	    + As nodes and relationships are created in the system, they can be used to make recommendations like "your friends also bought this product" or "when invoicing this item, these other items are usually invoiced." Or, it can be used to make recommendations to travelers mentioning that when other visitors come to Barcelona they usually visit Antonio Gaudi's creations. 
	    + An interesting side effect of using the graph databases for recommendations is that as the data size grows, the number of nodes and relationships available to make the recommendations quickly increases. The same data can also be used to mine information-for example, which products are always bought together, or which items are always invoiced together; alerts can be raised when these conditions are not met. Like other recommendation engines, graph databases can be used to search for patterns in relationships to detect fraud in transactions. 

* When not to use 
	- When you want to update all or a subset of entities - for example, in an analytics solution where all entities may need to be updated with a changed property - graph databases may not be optimal since changing a peroperty on all the nodes is not a straight-forward operation. Even if the data model works for the problem domain, some databases may be unable to handle lots of data, especially in global graph operations. 



* Database storage engine:
A database engine (or storage engine) is the underlying software component that
a database management system (DBMS) uses to create, read, update and delete (CRUD)
data from a database. E.g., MyISAM, InnoDB, Memory, Archive, NDB..
MyISAM vs InnoDB(default):http://blog.danyll.com/myisam-vs-innodb/
Comparison of all: http://zetcode.com/databases/mysqltutorial/storageengines/
Database engines are responsible for indexing, according to Wikipedia.








