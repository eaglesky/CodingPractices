Concepts.

CS75 video:

1. Web hosting service:
A web hosting service is a type of Internet hosting service that allows individuals
and organizations to make their website accessible via the World Wide Web. Web hosts
are companies that provide space on a server owned or leased for use by clients, as
well as providing Internet connectivity, typically in a data center.
Example: Bluehost, Dreamhost, Go Daddy, Host Gator, pair Networks.

2. Different types of web hosting service:
Shared, dedicated, VPS, Cloud.
https://hostingfacts.com/different-types-of-web-hosting/.

3. Vertical scaling:
Better hardware, like SSD.

4. Horizontal scaling:

5. Load balacing:
The DNS server can return the ip of load balancer instead of a server, and let the
load balancer decide which server the request should be sent to.
Load balancing strategies:
(1) Based on load of the server(how busy it is, the cpu usage).
(2) Store different types of files on different servers, and use the suffix of url
to discreminate them. 
(3) Round robin. Example: BIND(the most widely used Domain Name System (DNS) software
on the Internet) uses this strategy to resolve a host name --- same host name, but
different ip each time. The drawback of this strategy is that one or few server could
always receive requests that require most computation resource, making them much busier
than the rest. Another thing that can show it is a bad strategy is DNS caching, which
exists on the user's computer(maintained by the OS and browser). This caching is a
map of host name and ip address that will expire(clear) after a certain amount of
time(TTL). It is only used for speeding up the response time 
(https://www.lifewire.com/introduction-to-domain-name-system-817512). So if an user
keeps doing expensive work, it will always be done on the same server during TTL and
that server will be always busy. Therefore instead of relying on the DNS server to
do the load balancing, it is better to let the DNS server return the ip of the load
balancer.

Server-side sessions(http://stackoverflow.com/questions/3804209/what-are-sessions-how-do-they-work)
could cause problems for load balancing, because one session for a user is only stored
on one server. Solution: store all the sessions on a dedicated session server, or
the load balancer itself, which can be accessed by all servers. However what if the
server is down?
We could try using RAID to achieve data redundancy to some degree, but this is still
not a good solution, as it is possible that the whole server is down. A better way
to deal with it is to use multiple servers, which requires some syncing process.
Sticky session can also be a solution here, which can be implemented by storing an
id in the user's cookie and let LB to remember the mapping of that id to the ip of
the server the session belongs to.

Load Balancer choices:
Software:
ELB(AWS Elastic Load Balancing), HAProxy, LVS(Linux Virtual Server, http://www.linuxvirtualserver.org/whatis.html)
Hardware:
Barracuda, Cisco, Citrix, F5..


6. Caching.
(1) File based caching. Storeing a new file(html file) when new data is entered, like
what is done by Craigslist. The upside of this approach is that the html file doesn't
have to be regenerated everytime it's visited. The downside of it is due to the redundancy,
it is hard to change the common style of the pages. And it could use too much space.
(2) MySQL caching.
query_cache_type = 1 is enough to enable it. Used for cache the query result.
(3) Memcached
Cache data and objects in the RAM. Use LRU to purge old data when it is full.

7. Database replication
(1)Master-slave.
As the master-slave replication is a one-way replication (from master to slave),only
the master database is used for the write operations, while read operations may
be spread on multiple slave databases(and the master too).
Upside: data replication due to the several backup slaves. Load balancing read to
the slaves so that it can process large amount of traffic and scale out easily.
Downside: single-point-failure of the master db.
(2)Master-master.
Upside: 
* If one master fails, other masters continue to update the database.
* Masters can be located in several physical sites, i.e. distributed across the network.
Downside:
Very hard to preserve absolute consistency. 
http://stackoverflow.com/questions/21196000/mysql-master-master-data-replication-consistency

How to do the failover?? What does the consistency here mean?

8. Example 1: Load Balancing + Replication
(1)Load Balancer and MySQL master are the single points of failures.
Multiple load balancers: active - active or active - passive.
One needs to send its heartbeats(packages) every period of time to another.
http://serverfault.com/questions/388543/load-balancing-active-active-config-and-dynamic-server-addition

9. Example 2: with partitioning.

10. Security.
Open tcp port 80(http) and tcp port 443(https) for the traffic coming into the LBs.
Opening tcp port 80 for the inside traffic after first layer of LB can save putting
SSL certificate on all of the web servers.
Open tcp port 3306(MySQL db server default)

Knowledge:

* Computer Protocols- TCP/IP, POP, SMTP, HTTP, FTP and More
http://vlaurie.com/computers2/Articles/protocol.htm


* TCP vs UDP
https://www.howtogeek.com/190014/htg-explains-what-is-the-difference-between-tcp-and-udp/
UDP is less reliable but much faster, so it is preferable for transmitting time-critical
data, like live video stream and online game data.


* Cookies: Http Cookies and third-party cookies.
Drawbacks of cookies:https://en.wikipedia.org/wiki/HTTP_cookie#Drawbacks_of_cookies


* Three ways of managing sessions:
https://www.youtube.com/watch?v=32UGARg8AzU
Cookies
URL rewriting, Hidden fields
https://www.youtube.com/watch?v=xGAVFsLfn2w
https://www.youtube.com/watch?v=Pv3FST7OcvQ


* RAID(Redundant array of inexpensive disks):
It is a data storage virtualization technology that combines multiple physical disk
drive components into a single logical unit for the purposes of data redundancy,
performance improvement, or both.

RAID0: Uses data striping(technique of segmenting logically sequential data, such
as a file, so that consecutive segments are stored on different physical storage
devices) to perform concurrent read and write, so that the performance could be improved
by the number of disks. No data redundancy involved.

RAID1: Uses data mirroring to implement redundancy. Typically two idendical hard drives.
Write throughput is always slower because every drive must be updated, and the slowest
drive limits the write performance. 

RAID10: A combination of above.

* CAP theorem:
It is impossible for a distributed computer system to simultaneously provide more
than two out of three of the following guarantees:
Consistency, Availability, Partition Tolerance.
CAP is frequently misunderstood as if one had to choose to abandon one of the three
guarantees at all times. In fact, the choice is really between consistency and availability
for when a partition happens only; at all other times, no trade-off has to be made.
https://en.wikipedia.org/wiki/CAP_theorem
Strictly, most of the systems are not CAP-available if P happens. What this theorem
really says is that when P happens, you need to make a trade-off between C and A.
But you can never achieve 100% for both. E.g., if master-slaves is used for each shard,
and if read and write are performed on master, then strong consistency can be guaranteed,
but the level of availability is low when P happens between the router and the master.
We can change it by allowing read on slaves, which makes it no longer CAP-consistent
and increases the level of availability, but it is still not 100% available since
the write request could fail in such case.
https://martin.kleppmann.com/2015/05/11/please-stop-calling-databases-cp-or-ap.html

* Eventual Consistency, Strong Eventual Consistency, Strong Consistency
http://stackoverflow.com/questions/29381442/eventual-consistency-vs-strong-eventual-consistency-vs-strong-consistency
Another good article on eventual consistency and strong consistency:
https://cloud.google.com/datastore/docs/articles/balancing-strong-and-eventual-consistency-with-google-cloud-datastore/#h.w3kz4fze562t
As I understand it, strong eventual consistency uses CRDT to avoid conficts and thus
the data could be consistent after some time without resolving conficts before propagating
the update.
Tradeoff between consistency and latency:
http://cs-www.cs.yale.edu/homes/dna/papers/abadi-pacelc.pdf
Saved as CAP_tradeoff.pdf

* ACID transaction:
Atomicity. In a transaction involving two or more discrete pieces of information,
either all of the pieces are committed or none are.

Consistency. A transaction either creates a new and valid state of data, or, if
any failure occurs, returns all data to its state before the transaction was started.

Isolation. A transaction in process and not yet committed must remain isolated
from any other transaction.

Durability. Committed data is saved by the system such that, even in the event of
a failure and system restart, the data is available in its correct state.

* Database index:
http://www.programmerinterview.com/index.php/database-sql/what-is-an-index/
Typically database index is a datastructure like B tree(non-binary self-balancing
tree)

* Database normalization and denormalization:
https://www.essentialsql.com/get-ready-to-learn-sql-database-normalization-explained-in-simple-english/
http://www.vertabelo.com/blog/technical-articles/denormalization-when-why-and-how

* Ways of improving database query performance:
1. Optimizing the query itself, add caching.
2. Indexing.
3. Denormalization.

* Database partitioning.
https://en.wikipedia.org/wiki/Partition_(database)
Horizontal partitioning, or sharding in the distributed setting.
Vertical partitioning


* DBMS types:
https://www.youtube.com/watch?v=jSXxrTNZwXA
Relational, Use SQL: MySQL
Object-oriented, Use OQL: ObjectDB.
NoSQL:
Good introduction video: https://www.youtube.com/watch?v=qI_g07C_Q5I
Hard to define, usually has characteristics:
Non-relational, cluster-friendly, schema-less, open-source.
Types:
Key-value: Redis(CP?), Memcached, Oracle NoSQL database.
Document: MongoDB(CP)
Column: HBase(CP), Cassandra(AP)
Graph: Neo4j(CP)

	** Redis
	Introduction and Data Model: https://redis.io/topics/introduction
	Persistence: https://redis.io/topics/persistence
				 http://oldblog.antirez.com/post/redis-persistence-demystified.html
	Cluster and sharding: https://redis.io/topics/partitioning
			 https://redis.io/topics/cluster-tutorial
	vs Memcached, and why use Redis:
	http://stackoverflow.com/questions/7888880/what-is-redis-and-what-do-i-use-it-for

	** MongoDB
	Introduction and Data Model: https://www.youtube.com/watch?v=pWbMrx5rVBE
	Sharding: https://docs.mongodb.com/manual/sharding/
	Architecture: https://www.mongodb.com/presentations/webinar-everything-you-need-know-about-sharding?jmp=docs&_ga=1.78388884.1635526347.1487659117

	** HBase
	Introduction and Data Model: http://hbase.apache.org/0.94/book/datamodel.html
	Data Model and Architecture:  https://www.edureka.co/blog/hbase-architecture/

* SQL vs NoSQL
1. Consistency: 
SQL: Strong Consistency
NoSQL: Trade consistency for availability and partition tolerance, usually eventual
consistency. But still can achieve strong consistency.



* Database storage engine:
A database engine (or storage engine) is the underlying software component that
a database management system (DBMS) uses to create, read, update and delete (CRUD)
data from a database. E.g., MyISAM, InnoDB, Memory, Archive, NDB..
MyISAM vs InnoDB(default):http://blog.danyll.com/myisam-vs-innodb/
Comparison of all: http://zetcode.com/databases/mysqltutorial/storageengines/
Database engines are responsible for indexing, according to Wikipedia.








