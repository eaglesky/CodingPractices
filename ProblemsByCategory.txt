Reference Books:
(1) Cracking the coding interview
(2) Robert Sedgewick's Algorithms
(3) Introduction to algorithms
(4) Head first Java
(5) Leetcode
(6) Element of Programming Interviews(EPI)

1. Arrays and HashTables

Knowledge:
(1) Hash Tables -- implementation, performance, collision. Iteration each element
in it usually requires iterate each bucket.
(2) Resizeable array
	Implementation: Vector(C++), ArrayList(Java)
	Performance: get, set is O(1), amortized time of add is O(1) and why. 
(3) Basic language syntax for array(fixed and dynamic), hash map and hash set.
(4) In java, it's better to use constructor to get the shallow copy of ArrayList than
calling the clone method, since List interface does not have clone method.
(5) Implementation of equals and hashCode methods in Java(See <<Effective Java>>,
http://www.angelikalanger.com/Articles/JavaSolutions/SecretsOfEquals/Equals.html)

Problems:
(1)[Leetcode]First Missing Positive(Algorithm and Implementation*)
(2) K Sum problems. Can be solved using two approaches:
    a. Sort the input array first. Then using two pointers starting from the beginning
    and the end of the array, moving one of them towards the other each time based
    on the comparison of the sum of the two elements and target, until they meet.
    The two pointers process takes O(n) time. No extra space needed.
    b. Using a hash set of list of n elements to record the results and remove duplicates.
    Sort the input array first if K > 2. Cache the sums and their corresponding elements
    while iterating the array. The result hash set has to be used to remove the duplicates!

    No matter which approach to use, divide K into two parts first. Iterate the second part
    and hash or iterate using two pointers on the first part.

    (2.1) Two sum
        (2.1.1) Input array is random, find out one solution.
            - [Leetcode] Two sum.
        (2.1.2) Input array is random, find out all unique solutions.
    (2.2) Three sum
        (2.1.1) Input array is random, find out all unique solutions.
            - [Leetcode] Three sum.
            - [Leetcode] Three sum closest.
    (2.3) Four sum(Random input array, find out all unique solutions)
        -[Leetcode] Four sum.
(3) Remove duplicates(Maximum allowed duplicates == K). Two ways of checking duplicates!
    - [Leetcode] Remove Duplicates from Sorted Array(Best Algorithm*).
    - [Leetcode] Remove Duplicates from Sorted Array2(Best Algorithm*).
(4) Inward two pointers:
    - [Leetcode] Previous three sum problems.
    - [Leetcode] Container with most water(Algorithm)
    - [Leetcode] Trapping rain water(Multiple Algorithms* and implementation*)


2. Strings

Knowledge:
(1)JAVA: String, StringBuilder and char[]. StringBuilder is essentially a wrapper
of dynamic char array , and append(string) basically copy each character from input
string to the end of existing char array. When deleting, it will shift the characters
after those deleted forward. To remove the last element in the StringBuilder, just
use sb.setLength(sb.length() - 1).
(2)Palindrome.
    (2.1)Definition. Check if a string is palindrome can be easily done in O(n) time.
    (2.2)Check if concatenation of two strings is a palindrome. The reverse of the
    second string has to be the 1)the prefix of the first string, and the rest of
    the first string is a palindrome, or 2)the first string is the prefix of the reverse
    of second string, and the rest of the reversed string is a palindrome. [Leetcode]Palindrome
    Pairs in the Trie part.
(3)Don't forget the edge case when the string is empty! If this happens, for loop
on the string won't happen!

Problems:
(1)[Leetcode]Integer To Roman(Algorithm*)
(2)[Leetcode]Roman To Integer(Algorithm*)
(3)Sliding window approach for substring problems:
    * Think about why sliding window approach would work first. It basically considers
    each substring that starts with the character at the left pointer and skip some
    by moving the left pointer. The substring within the sliding window(before the
    right pointer) often satisfies a certain condition. And usually the substrings
    starting from the characters in between don't satisfy that condition.
    * A map of character to position or character to count should be created at the
    beginning. Sometimes one may not be enough. Especially when there are multiple
    input strings.
    * The main for loop is moving the right pointer and check each character to see
    if it should stop and begin moving the left pointer. Need to think very carefully
    about this check. When the check doesn't pass, usually we need to update the map,
    in some ways. (Sometimes the map should always be updated)
    * If the above check passes, then an inner loop should be performed to move the
    left pointer. Remember to update the result(max/min length) first. Depending on
    the specific problem, the left pointer can or cannot be moved to the destination
    directly. Also during this process we might need to remove or change some entries
    in the map.
    * Return the max/min result. May need to do one more comparision.

    - [Leetcode]Longest Substring Without Repeating Characters(Best Algorithm* and
    Implementation),
    - [Leetcode]Longest Substring with At Most K Distinct Characters(Algorithm* and
    Implementation*)
    - [Leetcode]Minimum Window Substring(Algorithm* and Implementation*)
    - [Leetcode]Substring with Concatenation of All Words(Algorithm* and Implementation*)


3. Linked Lists

Knowledge:
(1)Java: LinkedList class -- double linked list, performance
(2)Two pointers technique is frequently used! The diff between any two given linked
list can always be found in O(m+n) time.
(3)Two pointers iteration on two linked lists(one on each of them):
    (3.1)while (p != null || q != null) {
            if (p == null) {
                operation on q;
                q = q.next;
            } else if (q == null) {
                operation on p;
                p = p.next;
            } else {
                operation on both p and q(might have more branches here)
                p = p.next;
                q = q.next;
            }
        }
    (3.2)while (p != null && q != null) {
            operation on both p and q.(might have more branches here)
            p = p.next;
            q = q.next;
        }
        while (p != null) {
            operation on p.
            p = p.next;
        }
        while (q != null) {
            operation on q.
            q = q.next;
        }
    (3.3)(probably best): while(p != null || q != null) {
                              if (p != null && (q == null || condition_of_iterate_p))
                              {
                                    operation on p.
                                    p = p.next;
                              } else {
                                    operation on q.
                                    q = q.next
                              }
                          }
   The above implementations can also be appied to two pointers iteration on arrays
   or strings. E.g. The merge function of Merge Sort. 
(4)Sometimes we can use the input pointers to reduce the number of pointers created.
(5)It is possible to delete a node only by using that pointer if that node is not
the head or tail --- by shifting the contents of the following nodes toward it and
remove the last one.
(6)Adding dummy node to the front a linked list can be convenient for iterating over
the list using two pointers, especially if we want to remove the first node, or insert
in front of the first node. Think carefully about edge cases involving the head node
if we do not want to add the dummy node(for node finding problems, think about the
case when there is only one node in a list).
(7)Edge cases: (think normal case first), insert/remove the first/last node, one node
linked list, null list.
(8)Three approaches for reversing linked list and their implementation(see below).

Problems:
(1)Node finding:
    - [Leetcode]Intersection Of Two Linked Lists(Best Algorithm* and Best Implementation*)
 Remember this algorithm(including the first trial)!
    - [Leetcode]Linked List Cycle II(Algorithm* and Implementation*)
(2)Remove nodes: 
    - [Leetcode]Remove Nth Node From End of List(Implementation, practice dummy node,
    two pointers moving and edge case thinking)
    - [Leetcode]Remove duplicates from sorted list I(easy) and II(Implementation*)
    - Generalization of above to allow K duplicates -- Remove duplicates from sorted
    list III.(Implementation* -- multiple cases)
(3)Reverse nodes: 
	(3.1). Basic head insertion(Iterative and recursive) -- creating a new linked list,
    original head pointer will become tail pointer, and the new head pointer keeps
    updating. No need for the dummy node.
	   - [Leetcode] Reverse Linked List(Implementation, recursive algorithm*)
	(3.2). Incremental head insertion -- This process includes node removing and node
    insertion. Must add dummy node. Must start from the second node(cur node start
    from curTail.next) and use a pointer pointing to the tail node(curTail is fixed!)
    that other nodes are inserted before.
	   - [Leetcode]Swap Nodes in Pairs(Implementation)
	   - [Leetcode]Reverse Nodes in K-Group(Algorithm* and Implementation*)
	   - [Leetcode]Reverse Linked List II(Implementation*)
	(3.3). Tail insertion. Inserting each node right after the original tail node. Need
    to first aquire pointer to the tail node and then start from the first node. Original
    tail node will become new head node. Pointer to the original head node need to
    be stored or it will be lost.
    - [Leetcode]Reverse Nodes in K-Group(Algorithm* and Implementation*)
(4)Re-arrange nodes:
    Removing nodes first, and then either insert them into the original list or a
    new list. The latter way requires creating a new dummy node and tail node for
    appending, more nodes than the former way but could be simpler. The former way
    need to deal with some special cases, like removing and inserting into the old
    place, which could affect the next position of the pointer.
    - [Leetcode]Rotate List(Implementation, practice two pointers moving--two ways)
    - [Leetcode]Partition List(Best algorithm*)
(4)Copy linked list:
	- [Leetcode]Copy List with Random Pointer(Algorithm*, two approaches)


4. Stack and Queue

Knowledge:
(1)stack can be implemented as resizable array or linked list; queue can be implemented
as cyclic array, double resizeable array or linked list.
(2)Java implemenation: 
Interfact Deque<E>, push(E item), pop(), peek(). 
Interface Queue<E>, offer(e), poll(), peek(). 
Iteration using iterator and descendingItarator -- different results!
Both of them can be implemented as class ArrayDeque<E>, which is very likely a double
direction resizeable array. According to java doc, "This class is likely to be faster
than Stack when used as a stack, and faster than LinkedList when used as a queue".
The Deque interface usually doesn't allow null element, as peek() returns null when
the deque is empty. peek() does not throw any exceptions. ArrayDeque doesn't permit
null element while LinkedList does. Stack interface permits null element too. However
try not to put null element in all cases.
(3)In some design problems, sometimes it is good to call peek() first in pop()/poll
().

Problems:
(1)[Leetcode]Simplify path(Implementation*)
(2)[Leetcode]Evaluate reverse polish notation(Implementation)
(3)[Leetcode]Min stack(Multiple algorithms*, practice conversion between primitive
types and Binary Numeric Promotion)
(4)[Leetcode]Implement queue using stacks(Algorithm*)
(5)[Leetcode]Implement stack using queues(Best Algorithm*)


5. Trees

Knowledge:
(1)Definition of tree, binary tree and binary search tree, and the differences between
them. For BST, definition can vary slightly with respect to equality, if there could
be duplicate values.
(2)Balanced vs Unbalanced. Two common types of balanced trees are red-black tree and
AVL tree. Usually the height of a balanced BST is O(log(N)).
(3)Definition of complete, full and perfect binary trees.
(4)Number of nodes in perfect binary tree: n = 2^k - 1 (k is the number of levels)
(5)Binary tree inorder, preorder and postorder traversal and their three implementations
(see related problems below, remember the implementation of them except Morris). --
N-ary trees?
(6)About Morris traversal: the basic idea is to use null right child of some nodes
to store the succedents beforehand and delete them afterhand. Preorder and inorder
are similar, since the right children are always traversed at last, and therefore
after traversing back through the thread pointer there is no need to visit the left
children again. However for postorder traversal, the parent node is traversed at last.
So after traversing back through the thread pointer, the left children have to be
visited reversely(only those nodes from the diret left child all the way down to the
right). It is also necessary to create a dummy node and(7) have its left child be the
root.
(7)Binary search tree:
    (7.1)Definition
    (7.2)Ascending order when doing inorder traversal on it
    (7.3)Search, Minimum, Maximum, Successor, Predecessor operations all run in
    O(h) time. h is the height of the BST. See the Leetcode practics for Successor
    implementation.
    (7.4)Insertion(easy) and Deletion(harder, see one example problem) can also run
    in O(h) time.
    (7.5)Selection and Rank. See Leetcode problem below.
    (7.6)Range query. See Robert's Algorithms. O(n) time and O(h) space
(8)Trie(Prefix tree/radix tree/digital tree):
    (8.1)Refer to Robert's Algorithms. Think of the chars on the link instead of on
    the node.
    (8.2)The map in each node can be implemented with hashmap or array.
    (8.3)See the first two leetcode problems for complete implementation of trie methods.
    (8.4)The value of each node can be boolean, integer, or even a String -- representation
    of the word from the root to the node. And this value can change and be used for
    de-duplication. E.g. [Leetcode] Word Search II.

Problems:
(1) Traversal:
    - [Leetcode]Binary tree inorder traversal(Algorithms* and Implementation*)
    - [Leetcode]Binary tree preorder traversal(Algorithms* and implementation)
    - [Leetcode]Binary tree postorder traversal(Algorithms* and implementation), it
    can be seen as a reverse of preorder traversal.
    - [Leetcode]Binary tree level order traversal I(Multiple algorithms* and best
    implementation of recursive solution*), II is just adding reverse to the end of
    the solution of I.
      [Leetcode]Zigzag level order traversal. Reverse the array for
    that level every two levels(or assign the values reversely when creating the array
    for that level).
      [Leetcode]Binary Tree right side view -- small variation of level order traversal.
    - [Leetcode]Symmetric Tree(Algorithm and Multiple Implementation*). Iterative
    solution using queue or stack can add the elements in any order.
    - [Leetcode]Balanced binary tree(Best Implementation*)
    - [Leetcode]Populating next right pointers in each node I and II(Implementation)
    - [Leetcode]Flatten binary tree to linked list(Multiple Algorithms*)
    - DFS for all the paths: [Leetcode]Path Sum I and II(Implementation). Current
    path needs to be copied first and then put into the result array.
(2) Recontruction of binary tree:
    - [Leetcode]Construct Binary Tree from Inorder and Postorder Traversal (Algorithm*
    and Implementation*), and Construct Binary Tree from Preorder and Inorder Traversal
    (same). Cannot construct the binary tree from Preorder and Postorder(why? When
    coming up with exceptions, try starting with the simplest examples)
    Note that if duplicates exist in the input array, there may not be unique tree!
(3) Binary Search Tree:
    - [Leetcode]Validate Binary Search Tree(Multiple algorithms* and Implementations*)
        -- this reveals an important attribute of BST when traversing it!
    - [Leetcode]Recover Binary Search Tree(Algorithm and Implementation). Note that
    this question assumes there are no duplicates in BST! What would be the solution
    if there could be duplicates?
    - [Leetcode]Convert Sorted Array to Binary Search Tree(Algorithms and Iterative
    Implementation*)
    - [Leetcode]Convert Sorted List to Binary Search Tree(Best Algorithm* and Implementations*),
    constructing tree from array can often be solved by bottom-up approach!
    - [Leetcode]Delete Node in a BST(Algorithms* and Implementation)
    - [Leetcode]Inorder Successor in BST(Algorithm*). This algorithm uses the ascending
    order attribute of BST so that it can run in O(h) time not in O(n) time. Therefore
    this algorithm works only when the target is INORDER successor and there are no
    duplicates in the tree. If duplicates are allowed, this algorithm can not gurantee
    that the node returned is INORDER successor. Example:
            13
          10
        9
          10(returned node)
            10 (look-up node)    
    This algorithm can be easily extended to implement Ceiling and Floor methods.
    - [Leetcode]Kth Smallest Element in a BST(Multiple Algorithms*)
(4) Trie:
    - [Leetcode]Implement Trie (Prefix Tree)(Full Implementation*, recursive solution
    of delete?)
    - [Leetcode]Add and Search Word - Data structure design(Implementation)
    - [Leetcode]Palindrome Pairs(Multiple Algorithms* and Implementations*).(Distinct
    indices (i, j) just means that i != j) One way to improve the speed of not optimal
    algorithm is consider caching some values when building the trie. Remember the
    edge cases for the second approach.


6. Graph

Knowledge:
(1)Representations(Refer to CTCI):
    (1.1)Adjacency list. V(number of Vertices) + E(number of edges) space for directed
    graph, or V + 2E for undirected graph. This is usually the preferred representation.
    Works well when accessing the neighbors is frequent. For fast edge lookup, just
    use hashset of integers(instead of list) as the element of arrays in the Graph
    class(Refer to the implementation of adjacency list in Robert's Algorithms)
    (2.2)Adjacency matrix. V*V space. Fast for edge lookup, easier to represent weights,
    but usually takes more space than adjacency list. And has no way to represent
    parallel edges.
(2)Traversal. Don't forget null input node and loops!
Also note that the following pseudocode only implements traversing from one node.
If the graph is not connected, then DFS and BFS below must be called for each node!
The following template is just used for implementation. Think about the problem itself
when considering the algorithm -- like what parameters to use in the recursive
functions and what they do in each recursion.
(2.1)DFS. Can be used for counting the number of connected components in
a graph, check if two vertices are connected, etc. Implemented recursively. Iterative
solution usually uses a stack. And a map of node to its parent can be created while
traversing to retrieve the paths.
    * Algorithm of DFS(node, visited)
        if node is null, return; //Can be omitted sometimes
        visit(node)
        visited[node] = true; //Usually a hashmap. Flexible, can vary a bit depending
                              //on the problem
        for (adjNode : node.adjNodes) {
            if (visited(adjNode) == false) {
                DFS(node, visited)
            }
        }
        Done;

    * Setting the visited node can also be done before iterating each adjNode, like
    below:
    Small variation of DFS(node)
        if node is null, return;
        visit(node);
        visited[node] = true;
        DFS(node, visited);
        Done;

    DFS(node, visited):
        for (adjNode : node.adjNodes) {
            if (visited(adjNode) == false) {
                visited[adjNode] = true;
                visit(adjNode);
                DFS(adjNode, visited);
            }
        }
        Done;

    * Checking if the adjNode is valid can also be done inside the recursive function
    --- at the beginning if the curNode is not valid, return.

    * Finding all the paths between two states:
        main:
            DFS(node, curPath, paths); //Initialize the capacity of curPath if possible!
            return paths;

        DFS(node, curPath, paths):
            if node is end node:
                paths.add(curPath.shallow_copy);
                return;

            for (adjNode : node.adjNodes) {
                if (isValid(adjNode, visited)) { //Cut branches in isValid
                    curPath.add(adjNode);
                    visited[adjNode] = true;
                    DFS(adjNode, curPath, paths);
                    curPath.removeLast; //This can be omitted if curPath is a fixed
                                        //size array. If so, upperId of the array
                                        //should be increased by 1 and passed to DFS
                                        //recursive function
                    visited[adjNode] = false;
                }
            }
            Done;

    * Variation of above:
        main is the same:
        DFS(node, curPath, paths):
            if node is end node:
                paths.add(curPath.shallow_copy);
                return;
            //isValid can also be called here instead of later, usually must be after
            //checking if the node is end node!
            curPath.add(node);
            visited[node] = true;
            for (adjNode : node.adjNodes) {
                if (isValid(adjNode, visited)) {
                    DFS(adjNode, curPath, paths);
                }
            }
            curPath.removeLast;
            visited[node] = false;
            Done;

(2.2)BFS. Usually used for finding the shorted path(s) between two vertices. Implemented
    iteratively using queue, O(V + E) time. 
    * Algorithm of BFS(node)
        If node is null, return; //queue usually doesn't allow null value
        Create queue q;
        q.enqueue(node);
        visited[node] = true; //Usually a hashmap. Flexible, can vary a bit depending
                              //on the problem
        while (!q.isEmpty) {
            curNode = q.dequeue();
            visit(curNode);
            for (adjNode : curNode.adjNodes) {
                if (visited(adjNode) == false) {
                    visited(adjNode) = true;
                    prev[adjNode] = curNode; //Record the predecessor, used when you
                                             //want the shorted path
                    q.enqueue(adjNode);
                }
            }
        }
        print(prev) // Print out the shortest path recursively, optional
        done;

    * Algorithm of level BFS(node), which can give the distance from the node being
    traversed to the source node
        If node is null, return; //queue usually doesn't allow null value
        Create queue q;
        q.enqueue(node);
        visited[node] = true; //Usually a hashmap. Flexible, can vary a bit depending
                              //on the problem
        for (level = 0; !q.isEmpty; ++level) {
            size = q.size();
            for (i = 0; i < size; ++i) {
                curNode = q.dequeue();
                visit(curNode);
                for (adjNode : curNode.adjNodes) {
                    if (visited(adjNode) == false) {
                        visited[adjNode] = true;
                        prev[adjNode] = curNode;  //optional
                        q.enqueue(adjNode);
                    }
                }          
            }
        }
        print(prev)  //optional
        done;

    * BFS(node, endNode) finding all the shortest paths: (see [Leetcode]Word Ladder2)
        If node is null, return; //queue usually doesn't allow null value
        Create queue q;
        q.enqueue(node);
        str2Dis[node] = 1; //Map of node to the distance to the source node(level),
                           //also used for checking if the node has been visited
        prevs[node] = emptyList; //Map of node to list of its predecessors
        shortestDis = -1;
        while (!q.isEmpty) {
            curNode = q.dequeue();
            curDis = str2Dis.get(curNode);
            if (shortestDis > -1 && curDis >= shortestDis) {
                break;
            }
            visit(curNode);
            for (adjNode : curNode.adjNodes) {
                if (adjNode == endNode) {
                    shortestDis = curDis + 1;
                }
                if (!str2Dis.containsKey(adjNode)) {
                    str2Dis[adjNode] = curDis + 1;
                    prev[adjNode].add(curNode); 
                    q.enqueue(adjNode);
                } else if (str2Dis.get(adjNode) == curDis + 1) {
                    prev[adjNode].add(curNode);
                }
            }
        }
        getPaths(endNode, prev, pathList, pathLists)
        done;

        getPaths(endNode, prev, pathList, pathLists): //DFS finding all paths
            prevNodes = pathList.get(endNode);
            if (prevNodes == null) { //There could be no path to endNode at all!
                return;
            }
            pathList.add(endNode); //If we add to the front here, then there is no
                                   //need to reverse later
            for (prevNode : prevNodes) {
                getPaths(prevNode, prev, pathList, pathLists);
            }
            if (prevNodes.isEmpty()) { //The root node has no predecessors
                pathListReversed = pathList.reverseCopy(); //Don't forget to make
                                                           //a copy first!
                pathLists.add(pathListReversed);
            }
            pathList.removeLastNode();
            done;


    * Bidirectional BFS. See [Leetcode]Word Ladder for implementation.

Problems:
(1)[Leetcode]Clone Graph, good practice for BFS and DFS. (Algorithms* and Implementations*)
(2)[Leetcode]Surrounded Regions. (Algorithms and Implementations*). For DFS, sometimes
we need to add some restrictions to prevent stack overflow.Remember BFS implementation
to this kind of problems.
(3)[Leetcode]Number of Islands. (Algorithms*)
(4)[Leetcode]Word Search. (Algorithm*)
(5)[Leetcode]Word Search II. (Algorithm and Best Implementation*)
(6)[Leetcode]Word Ladder I(Algorithms and Implementations*). Remember the implementation
of Bidirectional BFS.
(7)[Leetcode]Word Ladder II(Algorithms and Implementations*). Remember the implementation
of finding all shortest paths using BFS. 
(8)[Leetcode]Restore IP Addresses(Implementation*). '012' is invalid while '0' is
valid.
(9)[Leetcode]Combination Sum(Implementation). What's the DP solution?
(10)[Leetcode]Combination Sum II(Algorithm*). DP solution? Remember the way of thinking
combination related problems!
(11)[Leetcode]Combination Sum III(Implementation*).
(12)[Leetcode]N Queens. (Algorithm*)
(13)[Leetcode]Generate Parentheses. (Algorithm). DP solution?
(14)[Leetcode]Sudoku Solver(Implementation). DFS with return boolean check.



7. Permutations, Combinations and Subsets.
Knowledge:
(1)Factorial representation of Permutation: P(n,k) = n! / (n-k)! 
(2)Factorial representation of Combination: C(n,k) = n! / (k! * (n-k)!)
(3)(1 + X)^n = Sum(Cn,k * X^k), 0 <= k <= n
(4)C(n,k) = C(n-1, k-1) + C(n-1, k)
(5)Permutations, Combinations and Subsets can all be solved by standard DFS or iterative
solution based on induction. To remove duplicates, we can either use a hashtable or
sort the original array first and then compare the current number with the previous
one. Combinations and Subsets problems can also be solved using BitSet, but not recommended
as first trial.

Problems:
(1)[Leetcode]Permutations I and II (Multiple Algorithms*)
(2)[Leetcode]Permutation Sequence(Best Algorithm and Implementation*)
(3)[Leetcode]Combinations(Algorithms*)
(4)[Leetcode]Subsets I and II(Multiple Algorithms*)
(5)[Leetcode]Letter combinations of a phone number(Iterative Algorithm*). Remember
the iterative algorithm!



8. Heap

Knowledge(mainly come from Robert's Algorithms):
(1)Priority queue is a abstract data type, like an interface in Java, that can be
implemented with different concrete data structures -- unordered array, ordered array
, linked list or heap. The performance of the basic operations like max and insert
varies in all those implmentations(See Robert's Algorithms for the comparison chart).
(2)Heap is a concrete data structure that is typically used to implement priority
queue. Usually heap refers to binary heap, but could also refer to d-ary heaps. In
concept, a binary heap is a complete binary tree. Each node in the tree is larger
than or equal to the keys in that node's two children. The heap operations require
traversing not only down but also up, so in practice, heap is usually implemented
as an array.
(3)Attributions of Heap:
    (3.1)The largest key in a heap-ordered binary tree is found at the root.
    (3.2)The height of a complete binary tree of size N is ⎣lg N⎦ .
(4)Operations on heap:
    (4.1)parent, leftChild, rightChild. Simple O(1) operations on the indices.
    (4.2)Size of array and size of heap is different!
    (4.3)exchange two nodes.
    (4.4)Bottom-up reheapify (swim). O(lg N)
    (4.5)Top-down reheapify (sink). O(lg N)
    (4.6)Insert. Add a new key, increase heap size, call 3.4. O(lg N)
    (4.7)Remove the maximum/minimum(root), and return the new root key. Exchange last
    key with the root key, decrease heap size, call 3.5 to sink the root key. O(lg
    N).
    (4.8)Build heap. Call insert(3.6) one by one. O(nlogn), but if we do it from right
    to left: to call sink(3.5) from the halfway of the array to the left, it runs
    in O(2n) = O(n) time.The proof is in Introduction to Algorithms. This can convert
    an unordered array to a heap. 
    (4.9)Heap sort(ascending order): (http://algs4.cs.princeton.edu/24pq/Heap.java.html)
        Build max heap(3.8)
        while (N > 1) {
            swap(root, last element of the heap);
            N--  // Decrease the heap size by 1.
            sink(root);
        }
(5)Indexed priority queue(Robert's Algorithms). Puting indices into a PQ insead of
the keys directly, and compare the nodes based on the key(not the index!). What is
swapped during reheapfiying is the content of the array(the indices). Therefore when
implementing it using a heap, besides the heap array, we also need a map of index
to the key, which is often implemented with another array since the index is usually
an integer. The operation 3.7 for this case usually returns the index. And besides
the typical PQ operations, there are change(int k, Item item) method that change the
key associated with index k to a new key, which requires a third array storing the
actual array index for each index of the key(another map). For typical heap PQ, it
usually takes the array index directly so no mapping is needed. An useful applciation
is also provided in the book: merging multiple sorted streams.
Source code: http://algs4.cs.princeton.edu/24pq/IndexMinPQ.java.html



9. Sorting and Searching

Knowledge(mainly from Coding Manual and Robert's Algorithms):
(1)Source code for sortings is in Sortings.java.
(2)Insertion sort, bubble sort and selection sort. Although all of them run in O(n^2)
time using O(1) space, insertion sort is usually the most efficient(fastest, even
faster than other O(nlogn) sorting algorithms when the array is small), while bubble
sort is the least efficient. This can be seen from the source code, the number of
basic operations in each loop of bubble sort is simly larger than the other two. When
the input array is mostly or fully sorted, insertion sort can perform much less operations,
while selection sort still performs almost as many as usual. Selection sort generally
performs more comparisons than insertion sort, but less writes.
Also note that the first two algorithms are stable, while the selection sort is not.
Example: for [9, 3, 2, 9, 1], the first 9 will be swapped with 1, leading to a change
of relative order of the two 9s.
(3)Merge sort. O(nlogn) time. Needs auxiliary space. Can be implemented using top-down
or bottom-up approaches. The space usage can be reduced a bit by adding more array
copy operations and do in-place changes instead of returning a new array. The speed
can be further improved by using insertion sort instead of merge sort when the subarray
is small.
(4)Quick sort. Worst case O(n^2) time and on average O(nlogn) time. To make sure it
runs in O(nlogn), either the pivot is choosen randomly or the array is shuffled before
partitioning. Two partition schemes exist -- Lomuto(used in Introduction to Algorithms)
and Hoare(similiar to my implementation, which seems to be more popular, but not easy
to understand. Need to remember it).
As per Robert's Algorithms, the average performance of quick sort is usually better
than the other O(nlogn) sorting algorithms, due to fewer data movements and comparisons.
The speed can be further improved by using insertion sort instead of quick sort when
the subarray is small.
(5)Heap sort. The algorithm is in 8.3.9. O(nlogn) time and O(1) space, unstable. The
number of comparisons is simliar to quick sort, but the cache misses are much larger
than the other sorting algorithms, becasue the array entries are rarely compared with
nearby array entries(locality of reference is lower). Cache is always loaded in blocks
and each block contains data that are adjacent to each other. Thus quick sort still
outperforms heap sort most of the time.
(6)Linear time sorts.
    (6.1)Counting sort. It tries to put each input element directly to the destination
    according to the number of elements that are no greater than it, which is computed
    beforehand. <<Introduction to Algorithms>>
        * Counting sort is efficient if the range of input data is not significantly
        greater than the number of objects to be sorted. Consider the situation where
        the input sequence is between range 1 to 10K and the data is 10, 5, 10K, 5K.
        * It works as long as the input elements can be mapped to a range of integers.
        So even if the input elements are negative or characters, it could still work.
        * Counting sort is stable. Thus it can be used as a subroutine in radix sort.
    (6.2)Radix sort. This is useful when each of the input elements consists of several
    (preferably known and fixed) columns. In such case, this algorithm uses stable
    sort to sort from the least significant to the most significant column. E.g, if
    the input elements are d-digit integers:
    Radix-sort(A, d):
        for i = 1 to d {
            stable_sort(like counting sort) A on digit i;
        }
    If we do stable sort for each digit using linear sorts like counting sort, the
    radix sort runs in O(d(n+k)) time, or O(dn) since k is less than 10. However in
    practice radix can be easily outperformed by other sorting algorithms when d is
    larger than logn. Also radix sort requires more space and less flexible than the
    other in-place sorting algorithms. 
    https://www.quora.com/If-Radix-sort-has-a-better-time-complexity-why-is-quick-sort-preferred-both-in-APIs-and-in-terms-of-interviews
    Overall, radix sort is a stable sort.
(7)Binary search. 
    (7.1)The goal is to find a certain element(or the largest element that is smaller
    than it, or the smallest element that is larger than it, etc)in a sorted array.
    (7.2)Cases to consider:
        * Valid case, including when the target element is on the edge.
        * Target element is within the range of the array but not contained in the array
        * Target element is out of the range of the array, either smaller than the
        minimum element in the array or greater than the maximum element in the array.
        * For above cases, don't forget the case when the input array has no or only
        one element.
    (7.3)Type of search problems and its implementations. General idea is to start
    with initial range of candidates [low, high], compare target with a[mid](or a
    [low], a[high] if necessary), then narrow down the candidates by half and search
    in the new range. Pay attention to how mid value is calculated since we want the
    range to keep shrinking to 1. For problems that the range can not be cut down
    to half(time is more than O(logn)), low or high can be increased or decreased
    gradually.
        (7.3.1)Traditional problem -- return the index of the element if found, otherwise
        return -1:
            int binarySearch(int[] a, int target) {
                int low = 0;
                int high = a.length - 1;
                int mid;
                while (low <= high) {
                    mid = low + (high - low)/ 2; //Avoid potential overflow,
                                                 //can also written as:
                                                 //low + ((high - low) >> 1)
                    if (target > a[mid]) {
                        low = mid + 1;
                    } else if (target < a[mid]) {
                        high = mid - 1;
                    } else {
                        return mid;
                    }
                return -1; // Error
            }

            int binarySearchRecursive(int[] a, int target, int low, int high) {
                if (low > high) return -1;// Error
                int mid = low + (high - low) / 2;
                if (target > a[mid]) {
                    return binarySearchRecursive(a, target, mid+ 1, high);
                } else if (target < a[mid]) {
                    return binarySearchRecursive(a, target, low, mid - 1);
                } else {
                    return mid;
                }
            }
        (7.3.2)Returns the index of first element that is greater than or equal to
        the target element. Returns n if all elements in the array of n are less than
        the target element.
                int firstGreaterEqual(int[] nums, int target) {
                    int low = 0;
                    int high = nums.length;
                    while (low < high) {
                        int mid = low + (high - low) / 2;
                        if (target > nums[mid]) {
                            low = mid + 1;
                        } else {
                            high = mid;
                        }
                    }
                    return low;
                }
        (7.3.3)Returns the index of last element that is less than or equal to the
        target element. Returns -1 if all elements in the array are greater than the
        target element.
                int lastLessEqual(int[] nums, int target) {
                    int low = -1;
                    int high = nums.length - 1;
                    while (low < high) {
                        int mid = high - (high - low) / 2;
                        if (target < nums[mid]) {
                            high = mid - 1;
                        } else {
                            low = mid;
                        }
                    }
                    return high;
                }
        When the target is within the range of the input array, returning low or high
        are all fine since they will be equal in the end, however when the target
        is not within the range, the end value of low is not equal to high!
        (7.3.4)Another way to deal with the above two problems is to intialize a variable
        at the begining to record the index of last found candidate. The rest is similar
        to the basic binary search and after the loop finishes, that variable should
        contain the final result. See EPI for the solutions to above problems.
        (7.3.5)Search in rotated sorted array. To search for the minium value, comparing
        the mid element with the highest element in the array is simpler than comparing
        it with the lowest one. Break the loop until low == high and return the final
        index. The minimum element always exists as long as the array is not empty.
        To search for the element in the array that is equal to the target, we first
        compare the mid element with the target and return if they are equal. Next
        we can either compare the mid element with the lowest or highest. It's better
        to compare with the highest too to be consistent. Then compare the target
        with the edge element according to different situations. The code is similar
        to 7.3.1.
        (7.3.6)Search a certain element that satisfies some condition. No explicit
        target value. The algorithm is usually to first check the middle value for
        a certain condition and use that condition to determine whether the next step
        is to go to the left half or the right half. The key is to determine what
        condition to use.

Problems:
Binary Search problems:
    (1)[Leetcode]Search Insert Position(Algorithms*). (7.3.2). If the
    target is in the array and there are more than one, then the returned index could
    be the id of any of those elements.
    (2)[Leetcode]Search for a Range(Algorithms*). (7.3.2) and (7.3.3)
    (3)[Leetcode]Sqrt(x). (Algorithm*). (7.3.2). Be careful about overflow!
    (4)[Leetcode]Search in rotated sorted array I and II(Algorithm*). (7.3.1)with
    changes. Remember the algorithm! (7.3.5)
    (5)[Leetcode]Find Minimum in Rotated Sorted Array I and II(Algorithm*). These
    problems return the min value rather than the id.(7.3.5)
    (6)[EPI]Search local minimum in partially sorted array(Algorithm).(7.3.6)
    Description is in CodingPractices/SearchLocalMinimum.java
    (7)[Leetcode]Median of two sorted arrays(Algorithm* and Implementation*).





10. Bit Manipulation

Problems:
(1)[Leetcode]Gray Code(Algorithm*). Remember the algorithm.






Implementation Utils:
1. Sorting an array:
    (1) Java:
            int[] nums;
            Arrays.sort(nums);//In place, stable, O(nlogn) time.

2. Copying an array to a new array:
    (1) Java:
        (1.1)System.arraycopy():
            int[] arr = {1,2,3,4,5};
            int[] copied = new int[10];
            System.arraycopy(arr, 0, copied, 1, 5);//5 is the length to copy
            System.out.println(Arrays.toString(copied));

        Output:
            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
            [0, 1, 2, 3, 4, 5, 0, 0, 0, 0]

        (1.2)Arrays.copyOf() returns a copy of original array:
            int[] copied = Arrays.copyOf(arr, 10); //10 the the length of the new array
            System.out.println(Arrays.toString(copied));
            copied = Arrays.copyOf(arr, 3);
            System.out.println(Arrays.toString(copied));

        Output:
            [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]
            [1, 2, 3]


3. Max and min Int
    (1) Java:
            Integer.MAX_VALUE;
            Integer.MIN_VALUE;

4. Absolute value:
    (1) Java:
            int absDiff = Math.abs(4-5);

5. Comparison of two numerical values:
    (1) Java:
            int maxOfTwo = Math.max(5, 4);
            int minOfTwo = Math.min(5, 4);

6. Find the maximum/minimum in an array as well as the index:
    (1) Java:
        input: int[] height
        int highestPos = 0;
        int result = 0;
        for (int i = 0; i < height.length; ++i) {
            highestPos = (height[i] > height[highestPos]) ? i : highestPos;
        }

7. Reverse a list:
    (1) Java: in place.
        java.util.Collections.reverse(List<?> list).

8. Convert String to Int:
    (1) Java:
            String number = "10";
            int result = Integer.parseInt(number);
            Integer result2 = Integer.valueOf(number);//if number is of int type,
            // this can also convert it to its Integer class

9. Count the occurence of each character in a string:
    (1) Java:
            String t = "aerwerrsdf";
            Map<Character, Integer> TcharCounts = new HashMap<>();
            for (int i = 0; i < t.length(); ++i) {
                int curCount = TcharCounts.getOrDefault(t.charAt(i), 0);
                TcharCounts.put(t.charAt(i), curCount + 1);
            }

10. Substring:
    (1) Java (public String substring(int beginIndex,
               int endIndex) ), beginIndex is inclusive and endIndex is exclusive
            "hamburger".substring(4, 8) returns "urge"
            "smiles".substring(1, 5) returns "mile"

11. Find the index of a character in a string:
    (1) Java:
            String str1 = "allen chin is a hero";
            int pos1 = str1.indexOf('a'); // 0
            int pos2 = str1.indexOf('a', 3); // 14
        
12. Concatinating strings and add delimiters between them:
    (1) Java 8: public static String join(CharSequence delimiter,
                          Iterable<? extends CharSequence> elements)
            List<String> strings = new LinkedList<>();
            strings.add("Java");strings.add("is");
            strings.add("cool");
            String message = String.join(" ", strings);
            //message returned is: "Java is cool"
            //This essentially iterate the input collection and append each element
            to a string builder with delimiter in between. And at last convert the
            string builder to string by calling sb.toString().

13. Initialization of multiple variables:
    (1) Java supports this, which can also be used in for-loop
        int a1 = 3, a2 = 5, a3 = 7;

14. Switch syntax:
    (1) Java:
        public String getTypeOfDayWithSwitchStatement(String dayOfWeekArg) {
         String typeOfDay;
         switch (dayOfWeekArg) {
             case "Monday":
                 typeOfDay = "Start of work week";
                 break;
             case "Tuesday":
             case "Wednesday":
             case "Thursday":
                 typeOfDay = "Midweek";
                 break;
             case "Friday":
                 typeOfDay = "End of work week";
                 break;
             case "Saturday":
             case "Sunday":
                 typeOfDay = "Weekend";
                 break;
             default:
                 throw new IllegalArgumentException("Invalid day of the week: " +
                 dayOfWeekArg);
         }
         return typeOfDay;
        }

15. Conversion between primitive types and Binary Numeric Promotion

16. Fastest way to return a list view of any number of elements:
    (1) Java:
         List<String> stooges = Arrays.asList("Larry", "Moe", "Curly");
         Note that the returned list is backed by the original array, not a copy,
         so modifying the original array will change the list!

17. Initialize elements of an array with same values:
    (1) Java:
        boolean[] validCols = new boolean[n];
        Arrays.fill(validCols, true);



